{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Understanding the Architecture and Performance {#understanding-the-architecture-and-performance}\n",
        "\n",
        "> üìñ Read the full article: [Build Trustworthy AI with Real-Time Citations Using Diffbot](https://codecut.ai/diffbot-llm-real-time-knowledge-graph-citation/)\n",
        "\n",
        "\n",
        "To understand how [Diffbot LLM](https://github.com/diffbot/diffbot-llm-inference?tab=readme-ov-file) delivers those reliable, cited responses, we need to examine the architectural philosophy behind its design and the performance metrics that validate this approach.\n",
        "\n",
        "### The GraphRAG philosophy {#the-graphrag-philosophy}\n",
        "\n",
        "Diffbot's approach represents a fundamental shift in AI architecture: instead of building ever-larger models that memorize more facts, they built smaller models that excel at finding and using external knowledge. This design challenges the \"bigger is better\" mindset, showing a 70B model with live data can outperform larger models on factual tasks.\n",
        "\n",
        "This architecture recognizes that facts change constantly while reasoning abilities remain stable. Rather than spending compute on memorizing Wikipedia, Diffbot fine-tuned models to become expert users of APIs, search engines, and code interpreters.\n",
        "\n",
        "For example, instead of memorizing static facts like \"Who is the CEO of Pfizer?\", Diffbot trains its model to make a real-time API call using a query like `type:Organization name:\"Pfizer\"` with the [Diffbot Knowledge Graph API](https://www.diffbot.com/products/knowledge-graph/).\n",
        "\n",
        "Here's a simplified version of the API's response:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"data\": [\n",
        "    {\n",
        "      \"ceo\": {\n",
        "        \"summary\": \"Greek-American pharmaceutical executive\",\n",
        "        \"image\": \"https://kg.diffbot.com/image/api/get?fetch=yes&url=g%3Cj7guSXzAoBWu.x0KwLZrUn.%5B%3CR0Aa4Hwygr9m6W%3Exl5G%60BkxmPAP1_w%7B%3C%3AVlDZ.Bv%3E\",\n",
        "        \"types\": [\"Person\"],\n",
        "        \"name\": \"Albert Bourla\",\n",
        "        \"diffbotUri\": \"http://diffbot.com/entity/EHPJc2wuRMGGvvptCHJ8jyg\",\n",
        "        \"targetDiffbotId\": \"EHPJc2wuRMGGvvptCHJ8jyg\",\n",
        "        \"type\": \"Person\"\n",
        "      }\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "```\n",
        "\n",
        "This API retrieves the latest CEO data by accessing the `data.ceo.name` field in the response (e.g., Albert Bourla), and includes a citation link to the original source.\n",
        "\n",
        "The result is a system that stays current without expensive retraining cycles and provides transparency that pure neural approaches cannot match.\n",
        "\n",
        "### Core components {#core-components}\n",
        "\n",
        "Diffbot's system has three main components working together. The Knowledge Graph contains over 10 billion entities and their relationships, continuously ingesting new information from millions of web pages since 2016. This creates a living map of factual knowledge spanning organizations, people, products, and events.\n",
        "\n",
        "The system's architecture includes:\n",
        "\n",
        "- **Knowledge Graph** ‚Äì 10+ billion entities with 1+ trillion facts, updated every 4-5 days\n",
        "- **Fine-tuned models** ‚Äì 8B parameter and 70B parameter versions that can run on a single A100 or dual H100 GPUs, respectively\n",
        "- **Real-time web search** ‚Äì Direct access to current web pages\n",
        "- **Code interpreter** ‚Äì Executes JavaScript to compute answers directly, ensuring accuracy and transparency without relying on guesswork.\n",
        "- **Multimodal capabilities** ‚Äì Understands and analyzes images through built-in visual reasoning tools\n",
        "\n",
        "Rather than memorizing facts, Diffbot fine-tuned the model to become an expert tool user, providing accurate results with full transparency.\n",
        "\n",
        "### Performance validation {#performance-validation}\n",
        "\n",
        "Diffbot LLM's benchmark performance validates its architectural advantages:\n",
        "\n",
        "- **FreshQA** ‚Äì 81% accuracy on real-time questions (highest among tested systems)\n",
        "- **MMLU-Pro** ‚Äì 70.36% on academic knowledge (best open-source under 100B parameters)\n",
        "- **SimpleQA** ‚Äì Outperformed all models including Perplexity Sonar Pro and Gemini-2.0-flash\n",
        "- **Citation accuracy** ‚Äì Every claim linked to verifiable sources\n",
        "\n",
        "The improvement comes from tool use rather than larger weights, showing external knowledge retrieval can match larger traditional models.\n",
        "\n",
        "## Getting started with Diffbot LLM {#getting-started-with-diffbot-llm}\n",
        "\n",
        "With the architectural foundation in place, let's walk through how to start using Diffbot LLM in practice.\n",
        "\n",
        "### Diffy ‚Äì the web UI {#diffy-the-web-ui}\n",
        "\n",
        "The fastest way to experience Diffbot LLM is through [Diffy.chat](https://diffy.chat/), the web interface that showcases the system's capabilities without requiring any setup. You can immediately test real-time information retrieval, citations, and multimodal requests to understand what makes Diffbot LLM different.\n",
        "\n",
        "![](https://codecut.ai/wp-content/uploads/2025/06/Group-1.png)\n",
        "\n",
        "Key features available through the web UI:\n",
        "\n",
        "- **Real-time web URL extraction** ‚Äì Summarize any webpage with proper attribution\n",
        "- **Knowledge graph querying** ‚Äì Access structured facts from Diffbot's trillion-fact database\n",
        "- **Image analysis** ‚Äì Upload images for visual understanding and interpretation\n",
        "- **JavaScript code interpreter** ‚Äì Get precise calculations and data processing\n",
        "- **Citation tracking** ‚Äì See exactly where every fact comes from with clickable sources\n",
        "\n",
        "The citation panel shows sources for each claim, giving you immediate insight into the transparency that sets Diffbot apart from traditional LLMs.\n",
        "\n",
        "### Installation and setup {#installation-and-setup}\n",
        "\n",
        "Getting started with the Diffbot LLM API requires just a few steps. Sign up for a free developer account at [app.diffbot.com/get-started](https://app.diffbot.com/get-started) to obtain your API token. The free tier provides sufficient credits for testing, with higher limits available for production use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pip install openai python dotenv\n",
        "touch .env  # Create a .env file\n",
        "echo \"DIFFBOT_API_TOKEN=your-token-here\" >> .env  # Add your token to a .env file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The API follows OpenAI's interface exactly, so you can integrate Diffbot LLM by simply changing the base URL and API key. This compatibility means no code restructuring ‚Äì your current OpenAI integration will work immediately with Diffbot's GraphRAG capabilities.\n",
        "\n",
        "### Your first query with citations {#your-first-query-with-citations}\n",
        "\n",
        "Here's a simple example demonstrating how Diffbot LLM returns responses with full citations:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "\n",
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "DIFFBOT_API_TOKEN = os.getenv(\"DIFFBOT_API_TOKEN\")\n",
        "\n",
        "diffbot_client = OpenAI(\n",
        "    base_url=\"https://llm.diffbot.com/rag/v1\",\n",
        "    api_key=DIFFBOT_API_TOKEN,\n",
        ")\n",
        "\n",
        "completion = diffbot_client.chat.completions.create(\n",
        "    model=\"diffbot-small-xl\",\n",
        "    messages=[{\"role\": \"user\", \"content\": \"What is GraphRAG?\"}],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this code, we:\n",
        "\n",
        "1. Initialize the OpenAI client with Diffbot's base URL for the RAG endpoint.\n",
        "2. Send a chat-style request to the diffbot-small-xl model with the user message \"What is GraphRAG?\"\n",
        "\n",
        "Here is the first few lines of the response:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(completion.choices[0].message.content[:1000])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```markdown\n",
        "**GraphRAG** stands for **Graph-based Retrieval Augmented Generation**, a method that integrates **knowledge graphs** with traditional **Retrieval Augmented Generation (RAG)** approaches to enhance the effectiveness and contextuality of AI responses.\n",
        "\n",
        "### Understanding GraphRAG {#understanding-graphrag}\n",
        "\n",
        "GraphRAG improves upon traditional RAG models by organizing data into a structured knowledge graph, which allows for more precise and context-aware results. Traditional RAG methods rely on semantic searches of unstructured text snippets, whereas GraphRAG leverages a hierarchical and community-based structure within the knowledge graph to facilitate complex queries and relationships ([Analytics Vidhya](https://www.analyticsvidhya.com/blog/2024/11/graphrag/#h-what-is-graphrag)).\n",
        "\n",
        "#### How Does GraphRAG Work?\n",
        "\n",
        "The **GraphRAG indexing package** is a data pipeline and transformation suite designed to extract structured data from unorganized text using **Large Language Models (LLMs)**. The standard pipeline includes\n",
        "```\n",
        "\n",
        "The response structure follows OpenAI's familiar format but cites a credible source‚Äî [Analytics Vidhya](https://www.analyticsvidhya.com/blog/2024/11/graphrag/#h-what-is-graphrag). This makes it easy to swap in Diffbot for any existing OpenAI-based setup when your application requires real-time information and verifiable citations from a knowledge graph.\n",
        "\n",
        "## Key Features and Capabilities {#key-features-and-capabilities}\n",
        "\n",
        "To understand Diffbot's capabilities, let's compare the outputs from Diffbot and GPT-4o. To do that, we'll first define a few helper functions: one to query Diffbot, one to query OpenAI, and another to print the model's response:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def query_model(query_text, model, base_url=None, api_key=None):\n",
        "    client_args = {}\n",
        "    if base_url:\n",
        "        client_args[\"base_url\"] = base_url\n",
        "    if api_key:\n",
        "        client_args[\"api_key\"] = api_key\n",
        "\n",
        "    client = OpenAI(**client_args)\n",
        "    return client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[{\"role\": \"user\", \"content\": query_text}],\n",
        "    )\n",
        "\n",
        "def query_diffbot(query_text, model=\"diffbot-small-xl\"):\n",
        "    return query_model(\n",
        "        query_text,\n",
        "        model=model,\n",
        "        base_url=\"https://llm.diffbot.com/rag/v1\",\n",
        "        api_key=DIFFBOT_API_TOKEN,\n",
        "    )\n",
        "\n",
        "def query_openai(query_text, model=\"o4-mini\"):\n",
        "    return query_model(query_text, model=model)\n",
        "\n",
        "def print_response(response):\n",
        "    print(response.choices[0].message.content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the following sections, we'll use these helper functions to ask questions and compare how each model responds.\n",
        "\n",
        "### **1. Real-time knowledge retrieval** {#1-real-time-knowledge-retrieval}\n",
        "\n",
        "Let's ask the model about the weather in Tokyo.\n",
        "\n",
        "**OpenAI:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "openai_completion_1 = query_openai(\"What is the weather in Tokyo?\")\n",
        "print_response(openai_completion_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```markdown\n",
        "1. Visit a weather website or app\n",
        "   ‚Ä¢ Weather.com / The Weather Channel\n",
        "   ‚Ä¢ AccuWeather\n",
        "   ‚Ä¢ Japan Meteorological Agency (JMA): https://www.jma.go.jp\n",
        "\n",
        "2. Ask a voice‚Äêassistant (Siri, Google Assistant, Alexa, etc.)\n",
        "...\n",
        "```\n",
        "\n",
        "The OpenAI model doesn't provide the weather directly. Instead, it suggests where you can find it, reflecting its lack of real-time access.\n",
        "\n",
        "**Diffbot:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "diffbot_completion_1 = query_diffbot(\"What is the weather in Tokyo?\")\n",
        "print_response(diffbot_completion_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```markdown\n",
        "### üå§Ô∏è Tokyo, Japan\n",
        "\n",
        "*May 28-31, 2025*\n",
        "\n",
        "Wed ‚òÅÔ∏è | 62-75¬∞F ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | üí®  5 mph | üíß 14%\n",
        "Thu üåßÔ∏è | 62-75¬∞F ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | üí®  5 mph | üíß 25%\n",
        "Fri üåßÔ∏è | 61-58¬∞F ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë | üí® 10 mph | üíß 94%\n",
        "Sat ‚õàÔ∏è | 72-61¬∞F ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | üí®  8 mph | üíß 93%\n",
        "\n",
        "*Last updated: 9:13 PM JST ([AccuWeather](https://www.accuweather.com/en/jp/tokyo/226396/weather-forecast/226396)) ([Weather.com](https://weather.com/weather/tenday/l/Minato+ku+Tokyo+Prefecture+Japan?canonicalCityId=89a9a327ec5fd290c4d12f51a20485cb))*\n",
        "```\n",
        "\n",
        "The Diffbot model returns a real-time weather forecast with detailed daily updates and citations. This indicates the model is capable of actively retrieving and integrating up-to-date, verifiable information into its responses.\n",
        "\n",
        "### **2. Code execution** {#2-code-execution}\n",
        "\n",
        "Now, let's ask a challenging math question that a traditional model would surely fail without access to a sandbox coding environment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "completion = query_diffbot(\n",
        "    \"Find the square root of 12394890235\",\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message.content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Output:\n",
        "\n",
        "````javascript\n",
        "The square root of **12394890235** is approximately **111332.34137033139**.\n",
        "\n",
        "<details>\n",
        "  <summary>Source</summary>\n",
        "\n",
        "  ```javascript\n",
        "  // Input value\n",
        "  var x = 12394890235;\n",
        "\n",
        "  // Logging the input value\n",
        "  console.log(\"Input value (x):\", x);\n",
        "\n",
        "  // Calculating the square root\n",
        "  var squareRoot = Math.sqrt(x);\n",
        "\n",
        "  // Logging the result\n",
        "  console.log(\"Square root of x:\", squareRoot);\n",
        "\n",
        "  // Final answer\n",
        "  console.log(\"Answer:\", squareRoot);\n",
        "  ```\n",
        "\n",
        "  Output:\n",
        "  ```\n",
        "  Input value (x): 12394890235\n",
        "  Square root of x: 111332.34137033139\n",
        "  Answer: 111332.34137033139\n",
        "  ```\n",
        "</details>\n",
        "````\n",
        "\n",
        "Both exponent calculations are precise and the final answer is correct as well with the sources being related to exponent calculations.\n",
        "\n",
        "### **3. Image analysis** {#3-image-analysis}\n",
        "\n",
        "Now, let's ask Diffbot multimodal questions that involve images. We will ask it to describe a nondescript URL of CodeCut's banner:\n",
        "\n",
        "![](https://codecut.ai/wp-content/uploads/2025/05/codecut-home-image.png)\n",
        "\n",
        "**OpenAI:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "_image_url = \"https://codecut.ai/wp-content/uploads/2025/05/codecut-home-image.png\"\n",
        "\n",
        "openai_completion_5 = query_openai(f\"Describe this image to me: {_image_url}\")\n",
        "print(openai_completion_5.choices[0].message.content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Again, GPT-4o is producing a fabricated response while Diffbot is accurate:\n",
        "\n",
        "**Diffbot:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "_image_url = \"https://codecut.ai/wp-content/uploads/2025/05/codecut-home-image.png\"\n",
        "diffbot_completion_5 = query_diffbot(f\"Describe this image to me: {_image_url}\")\n",
        "print(diffbot_completion_5.choices[0].message.content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```markdown\n",
        "This image features a modern laptop computer prominently in the center. The laptop is open to a coding interface, indicating its use for programming or software development purposes. The background of the image is clean and uncluttered, emphasizing the focus on the laptop and its digital content. The image has a resolution of 1200x1000 pixels.\n",
        "```\n",
        "\n",
        "This example verifies the multi-modal capabilities of Diffbot.\n",
        "\n",
        "## Self-hosting for privacy {#self-hosting-for-privacy}\n",
        "\n",
        "If your use-case involves high-stakes sensitive information like financial or medical databases, you can get all the benefits of the Serverless API locally by running a couple of Docker commands:\n",
        "\n",
        "For the 8B model, much smaller in disk size:\n",
        "\n",
        "```bash\n",
        "docker run --runtime nvidia --gpus all -p 8001:8001 --ipc=host -e VLLM_OPTIONS=\"--model diffbot/Llama-3.1-Diffbot-Small-2412 --served-model-name diffbot-small --enable-prefix-caching\"  docker.io/diffbot/diffbot-llm-inference:latest\n",
        "```\n",
        "\n",
        "For the larger 70B model with full capabilities:\n",
        "\n",
        "```bash\n",
        "docker run --runtime nvidia --gpus all -p 8001:8001 --ipc=host -e VLLM_OPTIONS=\"--model diffbot/Llama-3.3-Diffbot-Small-XL-2412 --served-model-name diffbot-small-xl --enable-prefix-caching --quantization fp8 --tensor-parallel-size 2\"  docker.io/diffbot/diffbot-llm-inference:latest\n",
        "```\n",
        "\n",
        "Once the application starts up successfully and you see a message like the following:\n",
        "\n",
        "```bash\n",
        "INFO:  Application startup complete.\n",
        "INFO:  Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n",
        "```\n",
        "\n",
        "You can run all the examples above by replacing the base URL with the endpoint `http://localhost:8001/rag/v1`.\n",
        "\n",
        "However, do note that these models require high-end GPUs like A100 and H100s to run at full precision. If you don't have the right hardware, consider using [RunPod.io](https://runpod.io/) which cost:\n",
        "\n",
        "- $5.98/hr for dual H100 GPU setup (total 160 GB VRAM)\n",
        "- $1.89/hr for a single A100 GPU setup (80 GB VRAM)\n",
        "\n",
        "![](https://codecut.ai/wp-content/uploads/2025/06/Group-2.png)\n",
        "\n",
        "If you want to see another example of how to run LLM's privately consider reading our article [Run Private AI Workflows with LangChain and Ollama](https://codecut.ai/private-ai-workflows-langchain-ollama/) for a different approach.\n",
        "\n",
        "## Building Real-World Applications with Diffbot and LangChain {#building-real-world-applications-with-diffbot-and-langchain}\n",
        "\n",
        "While the basic API integration shows Diffbot LLM's capabilities, combining it with LangChain unlocks the full potential for building production-ready applications that require sophisticated workflows and real-time knowledge.\n",
        "\n",
        "### LangChain + Diffbot basics {#langchain-diffbot-basics}\n",
        "\n",
        "Before building complex applications, you'll need to install the required LangChain packages and understand how to integrate them with Diffbot's API. Start by installing the necessary dependencies:\n",
        "\n",
        "```bash\n",
        "pip install langchain langchain-openai\n",
        "```\n",
        "\n",
        "LangChain provides a familiar interface for working with language models through its `ChatOpenAI` class. Since Diffbot LLM follows OpenAI's API format, integration requires only changing the base URL and API key:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    model=\"diffbot-small-xl\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    base_url=\"https://llm.diffbot.com/rag/v1\",\n",
        "    api_key=DIFFBOT_API_TOKEN,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This setup gives you access to all of LangChain's features while benefiting from Diffbot's real-time knowledge retrieval and citation capabilities. You can use the standard message format for simple interactions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "messages = [\n",
        "    (\"system\", \"You are a data scientist who writes efficient Python code.\"),\n",
        "    (\"human\", \"Given a DataFrame with columns 'product' and 'sales', calculates the total sales for each product.\"),\n",
        "]\n",
        "\n",
        "ai_msg = llm.invoke(messages)\n",
        "print(ai_msg.content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For more structured applications, LangChain's `ChatPromptTemplate` allows you to create reusable prompt templates with variables:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are a data scientist who writes efficient {language} code\",\n",
        "        ),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "chain = prompt | llm\n",
        "_result = chain.invoke(\n",
        "    {\n",
        "        \"language\": \"SQL\",\n",
        "        \"input\": \"Given a table with columns 'product' and 'sales', calculates the total sales for each product.\",\n",
        "    }\n",
        ")\n",
        "print(_result.content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The pipe operator ( `|`) creates a chain that flows data from the prompt through the language model, making it easy to build complex workflows with multiple steps.\n",
        "\n",
        "If you want to see another example of combining an LLM with Langchain you can read about it in our previous article [Build Smarter Data Science Workflows with DeepSeek and LangChain](https://codecut.ai/build-data-science-workflows-deepseek-langchain/).\n",
        "\n",
        "### Building a RAG application with Diffbot and LangChain {#building-a-rag-application-with-diffbot-and-langchain}\n",
        "\n",
        "Now let's build a production-level research assistant that combines document analysis with Diffbot's real-time knowledge. This application will analyze uploaded documents, extract topics, and provide current information about those topics with proper citations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "import json\n",
        "from typing import List, Dict\n",
        "\n",
        "class ResearchAssistant:\n",
        "    def __init__(self, diffbot_api_key: str):\n",
        "        self.llm = ChatOpenAI(\n",
        "            model=\"diffbot-small-xl\",\n",
        "            temperature=0.3,\n",
        "            base_url=\"https://llm.diffbot.com/rag/v1\",\n",
        "            api_key=diffbot_api_key\n",
        "        )\n",
        "        self.setup_chains()\n",
        "\n",
        "    def setup_chains(self):\n",
        "        # Chain for extracting topics from documents\n",
        "        self.topic_extraction_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "        Analyze the following document and extract 3-5 main topics or entities that would benefit\n",
        "        from current information. Return as a JSON list of topics.\n",
        "\n",
        "        Document: {document}\n",
        "\n",
        "        Topics (JSON format):\n",
        "        \"\"\")\n",
        "\n",
        "        # Chain for researching each topic\n",
        "        self.research_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "        Provide comprehensive, current information about: {topic}\n",
        "\n",
        "        Context from document: {context}\n",
        "\n",
        "        Include:\n",
        "        1. Current status and recent developments\n",
        "        2. Key statistics or data points\n",
        "        3. Recent news or updates\n",
        "        4. Relevant industry trends\n",
        "\n",
        "        Ensure all facts are cited with sources.\n",
        "        \"\"\")\n",
        "\n",
        "        # Chain for generating final report\n",
        "        self.report_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "        Create a comprehensive research report based on the document analysis and current research.\n",
        "\n",
        "        Original Document Summary: {document_summary}\n",
        "\n",
        "        Research Findings: {research_findings}\n",
        "\n",
        "        Generate a well-structured report that:\n",
        "        1. Summarizes the original document's main points\n",
        "        2. Provides current context for each major topic\n",
        "        3. Identifies any outdated information in the document\n",
        "        4. Suggests areas for further investigation\n",
        "\n",
        "        Include proper citations throughout.\n",
        "        \"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `ResearchAssistant` class defines three specialized chains for different stages of the analysis. Each chain has a specific role: topic extraction identifies what to research, research gathering collects current information, and report generation synthesizes everything into a cohesive analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "    def extract_topics(self, document: str) -> List[str]:\n",
        "        \"\"\"Extract main topics from the document for research.\"\"\"\n",
        "        chain = self.topic_extraction_prompt | self.llm | StrOutputParser()\n",
        "\n",
        "        try:\n",
        "            result = chain.invoke({\"document\": document})\n",
        "            # Parse JSON response to get topic list\n",
        "            topics = json.loads(result.strip())\n",
        "            return topics if isinstance(topics, list) else []\n",
        "        except (json.JSONDecodeError, Exception) as e:\n",
        "            print(f\"Error extracting topics: {e}\")\n",
        "            return []\n",
        "\n",
        "    def research_topic(self, topic: str, context: str) -> str:\n",
        "        \"\"\"Research current information about a specific topic.\"\"\"\n",
        "        chain = self.research_prompt | self.llm | StrOutputParser()\n",
        "\n",
        "        return chain.invoke({\n",
        "            \"topic\": topic,\n",
        "            \"context\": context\n",
        "        })\n",
        "\n",
        "    def generate_report(self, document: str, research_findings: List[Dict]) -> str:\n",
        "        \"\"\"Generate comprehensive report with current information.\"\"\"\n",
        "        # Create document summary\n",
        "        summary_prompt = ChatPromptTemplate.from_template(\n",
        "            \"Provide a concise summary of this document: {document}\"\n",
        "        )\n",
        "        summary_chain = summary_prompt | self.llm | StrOutputParser()\n",
        "        document_summary = summary_chain.invoke({\"document\": document})\n",
        "\n",
        "        # Format research findings\n",
        "        findings_text = \"\\n\\n\".join([\n",
        "            f\"**{finding['topic']}:**\\n{finding['research']}\"\n",
        "            for finding in research_findings\n",
        "        ])\n",
        "\n",
        "        # Generate final report\n",
        "        report_chain = self.report_prompt | self.llm | StrOutputParser()\n",
        "\n",
        "        return report_chain.invoke({\n",
        "            \"document_summary\": document_summary,\n",
        "            \"research_findings\": findings_text\n",
        "        })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These methods handle the core workflow: `extract_topics` identifies research targets, `research_topic` gathers current information using Diffbot's knowledge graph, and `generate_report` synthesizes everything into a comprehensive analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "    def analyze_document(self, document: str) -> Dict:\n",
        "        \"\"\"Complete document analysis with current research.\"\"\"\n",
        "        print(\"Extracting topics from document...\")\n",
        "        topics = self.extract_topics(document)\n",
        "\n",
        "        if not topics:\n",
        "            return {\"error\": \"Could not extract topics from document\"}\n",
        "\n",
        "        print(f\"Researching {len(topics)} topics...\")\n",
        "        research_findings = []\n",
        "\n",
        "        for topic in topics:\n",
        "            print(f\"  - Researching: {topic}\")\n",
        "            research = self.research_topic(topic, document)\n",
        "            research_findings.append({\n",
        "                \"topic\": topic,\n",
        "                \"research\": research\n",
        "            })\n",
        "\n",
        "        print(\"Generating comprehensive report...\")\n",
        "        final_report = self.generate_report(document, research_findings)\n",
        "\n",
        "        return {\n",
        "            \"topics\": topics,\n",
        "            \"research_findings\": research_findings,\n",
        "            \"final_report\": final_report,\n",
        "            \"status\": \"completed\"\n",
        "        }\n",
        "\n",
        "# Usage example\n",
        "assistant = ResearchAssistant(DIFFBOT_API_TOKEN)\n",
        "\n",
        "sample_document = \"\"\"\n",
        "Artificial Intelligence has made significant progress in natural language processing.\n",
        "Companies like OpenAI and Google have released powerful language models.\n",
        "The field of machine learning continues to evolve with new architectures and techniques.\n",
        "Investment in AI startups reached $25 billion in 2023.\n",
        "\"\"\"\n",
        "\n",
        "result = assistant.analyze_document(sample_document)\n",
        "print(result[\"final_report\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This workflow demonstrates how LangChain's orchestration capabilities combine with Diffbot's real-time knowledge to create applications that deliver current, cited information.\n",
        "\n",
        "You can extend this pattern for competitive intelligence, academic research, market analysis, or any application that benefits from combining document analysis with real-time knowledge."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}