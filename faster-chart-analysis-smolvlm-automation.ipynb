{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Motivation {#motivation}\n",
        "\n",
        "> ðŸ“– Read the full article: [Faster Chart Analysis with Hugging Face Vision Models](https://codecut.ai/faster-chart-analysis-smolvlm-automation/)\n",
        "\n",
        "\n",
        "Manually analyzing charts is time-consuming. Data teams spend hours examining dashboards, extracting insights from visualizations, and documenting findings - a process that doesn't scale when dealing with dozens of reports daily.\n",
        "\n",
        "```python\n",
        "# Current manual process: time-consuming chart analysis\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Load sales data and create visualizations\n",
        "df = pd.read_csv(\"quarterly_sales.csv\")\n",
        "charts = [\n",
        "    df.groupby('region').sum().plot(kind='bar'),\n",
        "    df.plot(x='date', y='revenue', kind='line'),\n",
        "    df.corr().style.background_gradient()  # Correlation heatmap\n",
        "]\n",
        "\n",
        "# Manual analysis required for each chart:\n",
        "# 1. Open and examine each visualization\n",
        "# 2. Identify patterns and trends visually\n",
        "# 3. Extract key insights manually\n",
        "# 4. Document findings for stakeholders\n",
        "```\n",
        "\n",
        "Automated insight extraction with human oversight changes this dynamic. Use AI to quickly analyze visualizations and generate initial insights, then review and refine the output. This approach reduces analysis time from hours to minutes while maintaining accuracy through human validation.\n",
        "\n",
        "## Getting Started {#getting-started}\n",
        "\n",
        "SmolVLM eliminates the complexity of traditional image analysis by enabling direct natural language queries about visual content.\n",
        "\n",
        "Let's start by loading the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import torch\n",
        "from transformers import AutoProcessor, AutoModelForVision2Seq\n",
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "# Load the processor and model\n",
        "model_id = \"HuggingFaceTB/SmolVLM-500M-Instruct\"\n",
        "processor = AutoProcessor.from_pretrained(model_id)\n",
        "model = AutoModelForVision2Seq.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "\n",
        "# Move model to available device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "SmolVLM setup explained:\n",
        "\n",
        "- `AutoProcessor`: Converts images and text into format the model understands\n",
        "- `AutoModelForVision2Seq`: Loads the actual SmolVLM neural network weights\n",
        "- `torch.float16`: Uses half-precision to reduce memory usage by 50%\n",
        "- `Device detection`: Automatically uses GPU if available for faster inference\n",
        "\n",
        "Now, let's create a helper function to analyze a single image with a natural language question:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def analyze_image_with_smolvlm(image, question, max_tokens=200):\n",
        "    \"\"\"Analyze an image with SmolVLM using a natural language question.\"\"\"\n",
        "    # Format input as chat conversation\n",
        "    messages = [{\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\"type\": \"image\"},\n",
        "            {\"type\": \"text\", \"text\": question}\n",
        "        ]\n",
        "    }]\n",
        "\n",
        "    # Convert to model input format\n",
        "    prompt = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
        "    inputs = processor(text=prompt, images=[image], return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # Generate response\n",
        "    generated_ids = model.generate(\n",
        "        **inputs, max_new_tokens=max_tokens, do_sample=True, temperature=0.3\n",
        "    )\n",
        "\n",
        "    # Extract and return the response text\n",
        "    response = processor.batch_decode(\n",
        "        generated_ids[:, inputs.input_ids.shape[1]:], skip_special_tokens=True\n",
        "    )[0]\n",
        "\n",
        "    return response"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The function above does the following:\n",
        "\n",
        "- `apply_chat_template`: Formats the conversation for SmolVLM's expected input structure\n",
        "- `processor()`: Tokenizes text and preprocesses images into tensors\n",
        "- `model.generate()`: Runs the actual AI inference with configurable parameters\n",
        "- `batch_decode()`: Converts model output tokens back to readable text\n",
        "\n",
        "Next, create a helper function to analyze multiple questions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def print_qa_results(questions, answers, separator_length=40):\n",
        "    \"\"\"Print question and answer pairs with formatted output.\"\"\"\n",
        "    for question, answer in zip(questions, answers):\n",
        "        print(f\"Question: {question}\")\n",
        "        print(f\"Answer: {answer}\")\n",
        "        print(\"-\" * separator_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Chart Analysis {#chart-analysis}\n",
        "\n",
        "Let's put our helper function to work by analyzing a real heatmap using natural language queries.\n",
        "\n",
        "We'll analyze this correlation heatmap:\n",
        "\n",
        "![Heatmap showing correlation matrix with color-coded values](https://codecut.ai/wp-content/uploads/2025/08/heatmap.png)\n",
        "\n",
        "Here are the questions we'll ask:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load a complex chart for analysis - financial correlation heatmap\n",
        "image_url = (\n",
        "    \"https://eodhd.com/financial-academy/wp-content/uploads/2023/12/heatmap_sector.png\"\n",
        ")\n",
        "image = Image.open(requests.get(image_url, stream=True).raw)\n",
        "\n",
        "# Ask questions about the chart\n",
        "questions = [\n",
        "    \"What type of chart is this?\",\n",
        "    \"What are the main trends shown in this visualization?\",\n",
        "    \"What insights can you derive from this data?\",\n",
        "]\n",
        "\n",
        "answers = [analyze_image_with_smolvlm(image, q) for q in questions]\n",
        "print_qa_results(questions, answers, separator_length=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Output:\n",
        "\n",
        "```text\n",
        "Question: What type of chart is this?\n",
        "Answer:  Heatmap.\n",
        "--------------------------------------------------\n",
        "Question: What are the main trends shown in this visualization?\n",
        "Answer: This is a sector heat map showing percentage allocation across financial sectors. Consumer Staples has the highest allocation, followed by Energy and Industrials sectors.\n",
        "--------------------------------------------------\n",
        "Question: What insights can you derive from this data?\n",
        "Answer: Key insight: Consumer-focused sectors (services and staples) dominate the market, with communication services also performing strongly.\n",
        "--------------------------------------------------\n",
        "```\n",
        "\n",
        "The model provides direct answers about chart type, trends, and insights without requiring manual preprocessing or specialized analysis tools.\n",
        "\n",
        "## Document Understanding {#document-understanding}\n",
        "\n",
        "SmolVLM excels at extracting information from documents, receipts, and forms. Let's test this with a receipt:\n",
        "\n",
        "![Receipt](https://codecut.ai/wp-content/uploads/2025/08/receipt-scaled.png)\n",
        "\n",
        "and ask the following questions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Analyze a receipt or invoice\n",
        "receipt_url = \"https://raw.githubusercontent.com/mistralai/cookbook/main/mistral/ocr/receipt.png\"\n",
        "receipt_image = Image.open(requests.get(receipt_url, stream=True).raw)\n",
        "\n",
        "# Document analysis questions\n",
        "document_questions = [\n",
        "    \"What type of document is this?\",\n",
        "    \"What is the total amount?\",\n",
        "    \"What items can you identify?\",\n",
        "]\n",
        "\n",
        "answers = [analyze_image_with_smolvlm(receipt_image, q, max_tokens=150) for q in document_questions]\n",
        "print_qa_results(document_questions, answers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Output:\n",
        "\n",
        "```text\n",
        "Question: What type of document is this?\n",
        "Answer:  This is an invoice or receipt for a parking permit.\n",
        "----------------------------------------\n",
        "Question: What is the total amount?\n",
        "Answer:  The total amount is $15.00.\n",
        "----------------------------------------\n",
        "Question: What items can you identify?\n",
        "Answer:  The text contains a list of items, but specific details about each item are not provided.\n",
        "----------------------------------------\n",
        "```\n",
        "\n",
        "## Image Content Summarization {#image-content-summarization}\n",
        "\n",
        "We can also use SmolVLM to generate a summary of an image.\n",
        "\n",
        "Let's use the following image:\n",
        "\n",
        "![Street scene](https://codecut.ai/wp-content/uploads/2025/08/street.jpeg)\n",
        "\n",
        "and ask the following questions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Analyze a street scene\n",
        "street_url = \"https://images.unsplash.com/photo-1449824913935-59a10b8d2000?w=500\"\n",
        "street_image = Image.open(requests.get(street_url, stream=True).raw)\n",
        "\n",
        "# Summarization prompts\n",
        "summary_prompts = [\n",
        "    \"What's the main activity happening here?\",\n",
        "    \"Summarize the key elements of this scene\"\n",
        "]\n",
        "\n",
        "answers = [analyze_image_with_smolvlm(street_image, q, max_tokens=250) for q in summary_prompts]\n",
        "print_qa_results(summary_prompts, answers, separator_length=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Output:\n",
        "\n",
        "```text\n",
        "Prompt: What's the main activity happening here?\n",
        "Response:  There are many people on the road in the image.\n",
        "--------------------------------------------------\n",
        "Prompt: Summarize the key elements of this scene\n",
        "Response:  A busy city street with a few people walking and a few cars.\n",
        "--------------------------------------------------\n",
        "```\n",
        "\n",
        "## Automated Business Intelligence with Chart Analysis {#automated-business-intelligence-with-chart-analysis}\n",
        "\n",
        "See how SmolVLM integrates into a real data analysis workflow. We'll create a sales performance chart and then analyze it with natural language queries.\n",
        "\n",
        "First, generate sample sales data and create the visualization:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Generate quarterly sales data\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = {\n",
        "    'Quarter': ['Q1 2024', 'Q2 2024', 'Q3 2024', 'Q4 2024'],\n",
        "    'Product A': [45000, 52000, 48000, 61000],\n",
        "    'Product B': [38000, 41000, 39000, 44000],\n",
        "    'Product C': [23000, 28000, 32000, 35000]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df.set_index('Quarter').plot(kind='bar', figsize=(10, 6))\n",
        "plt.title('Quarterly Sales Performance by Product')\n",
        "plt.ylabel('Sales ($)')\n",
        "plt.xticks(rotation=45)\n",
        "plt.savefig('sales_chart.png', dpi=300)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Sales Chart](https://codecut.ai/wp-content/uploads/2025/08/sales_chart-scaled.png)\n",
        "\n",
        "Now analyze the chart with SmolVLM using targeted business questions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from PIL import Image\n",
        "\n",
        "# Load the chart we just created\n",
        "chart_image = Image.open('sales_chart.png')\n",
        "\n",
        "questions = [\n",
        "    \"What quarter had the best overall performance?\",\n",
        "    \"Are there any concerning trends I should investigate?\"\n",
        "]\n",
        "\n",
        "for question in questions:\n",
        "    answer = analyze_image_with_smolvlm(chart_image, question)\n",
        "    print(f\"Q: {question}\")\n",
        "    print(f\"A: {answer}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Output:\n",
        "\n",
        "```text\n",
        "Q: What quarter had the best overall performance?\n",
        "A:  Q4 2024.\n",
        "\n",
        "Q: Are there any concerning trends I should investigate?\n",
        "A:  The sales figures for Q1 2024 and Q4 2024 are significantly higher than those for Q2 2024 and Q3 2024.\n",
        "```\n",
        "\n",
        "This workflow demonstrates SmolVLM's value in everyday data analysis: create visualizations with your preferred tools, then get instant insights through natural language queries.\n",
        "\n",
        "## Building a Web Dashboard {#building-a-web-dashboard}\n",
        "\n",
        "To make chart analysis accessible for non-technical stakeholders, you can create an interactive web dashboard using [Gradio](https://gradio.app/). This Python framework enables rapid deployment of machine learning applications with just a few lines of code.\n",
        "\n",
        "To use Gradio, start by installing it:\n",
        "\n",
        "```bash\n",
        "pip install gradio\n",
        "```\n",
        "\n",
        "Next, create a dashboard function that combines image upload with question input. This function uses the SmolVLM helper we defined earlier:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def dashboard_analysis(image, question):\n",
        "    if image is None:\n",
        "        return \"Please upload an image to analyze.\"\n",
        "\n",
        "    # Use the analyze_image_with_smolvlm function from earlier in the article\n",
        "    return analyze_image_with_smolvlm(image, question, max_tokens=200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If running this dashboard code independently, make sure to include the model loading and helper function from the \"Getting Started\" section above.\n",
        "\n",
        "The function handles image uploads and passes user questions directly to SmolVLM. Now build the Gradio interface with three components:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import gradio as gr\n",
        "\n",
        "dashboard = gr.Interface(\n",
        "    fn=dashboard_analysis,\n",
        "    inputs=[\n",
        "        gr.Image(type=\"pil\", label=\"Upload Chart or Visualization\"),\n",
        "        gr.Textbox(value=\"What are the key trends in this chart?\", label=\"Ask a Question\")\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Analysis Results\"),\n",
        "    title=\"SmolVLM Chart Analysis Dashboard\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Launch the dashboard to make it accessible to your team:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dashboard.launch(share=True)  # share=True creates public link"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The dashboard provides a clean interface where users upload charts and ask questions in natural language.\n",
        "\n",
        "\n",
        "![SmolVLM Chart Analysis Dashboard](https://codecut.ai/wp-content/uploads/2025/08/chart_analysis.png)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}