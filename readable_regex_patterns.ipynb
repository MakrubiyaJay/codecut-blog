{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset Generation\n",
        "\n",
        "> ðŸ“– Read the full article: [Choose the Right Text Pattern Tool: Regex, Pregex, or Pyparsing](https://codecut.ai/regex-pregex-pyparsing-text-pattern-matching-guide/)\n",
        "\n",
        "\n",
        "Let's create sample datasets that will be used throughout the article. We'll generate customer support ticket data using the [Faker](https://codecut.ai/faker-python-generate-test-data/) library:\n",
        "\n",
        "Install Faker:\n",
        "\n",
        "```bash\n",
        "pip install faker\n",
        "```\n",
        "\n",
        "First, let's generate customer support tickets with simple contact information:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from faker import Faker\n",
        "import csv\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "fake = Faker()\n",
        "Faker.seed(40)\n",
        "\n",
        "# Define phone patterns\n",
        "phone_patterns = [\"(###)###-####\", \"###-###-####\", \"### ### ####\", \"###.###.####\"]\n",
        "\n",
        "# Define email TLDs\n",
        "email_tlds = [\".com\", \".org\", \".io\", \".net\"]\n",
        "\n",
        "# Generate phone numbers and emails\n",
        "phones = []\n",
        "emails = []\n",
        "\n",
        "for i in range(4):\n",
        "    # Generate phone with specific pattern\n",
        "    phone = fake.numerify(text=phone_patterns[i])\n",
        "    phones.append(phone)\n",
        "\n",
        "    # Generate email with specific TLD\n",
        "    email = fake.user_name() + \"@\" + fake.domain_word() + email_tlds[i]\n",
        "    emails.append(email)\n",
        "\n",
        "# Define sentence structures\n",
        "sentence_structures = [\n",
        "    lambda p, e: f\"Contact me at {e} or {p} to resolve this issue.\",\n",
        "    lambda p, e: f\"You can reach me by phone ({p}) or email ({e}) anytime.\",\n",
        "    lambda p, e: f\"My contact details: {e} and {p}.\",\n",
        "    lambda p, e: f\"Feel free to call {p} or email {e} for assistance.\"\n",
        "]\n",
        "\n",
        "# Create CSV with 4 rows\n",
        "with open(\"data/tickets.csv\", \"w\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"ticket_id\", \"message\"])\n",
        "\n",
        "    for i in range(4):\n",
        "        message = sentence_structures[i](phones[i], emails[i])\n",
        "        writer.writerow([i, message])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set the display option to show the full width of the columns:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pd.set_option(\"display.max_colwidth\", None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load and preview the tickets dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_tickets = pd.read_csv(\"data/tickets.csv\")\n",
        "df_tickets.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| ticket_id | message |\n",
        "|-----------|---------|\n",
        "| 0 | Contact me at nichole70@kemp.com or (798)034-325 to resolve this issue. |\n",
        "| 1 | You can reach me by phone (970-295-1452) or email (russellbrandon@simon-rogers.org) anytime. |\n",
        "| 2 | My contact details: ehamilton@silva.io and 242 844 7293. |\n",
        "| 3 | Feel free to call 901.794.1337 or email ogarcia@howell-chavez.net for assistance. |\n",
        "\n",
        "## Simple Regex: Basic Pattern Extraction\n",
        "\n",
        "Regular expressions (regex) are patterns that match text based on rules. They excel at finding structured data like emails, phone numbers, and dates in unstructured text.\n",
        "\n",
        "### Extract Email Addresses\n",
        "\n",
        "Start with a simple pattern that matches basic email formats, including:\n",
        "\n",
        "- Username: `[a-z]+` - One or more lowercase letters (e.g. `maria95`)\n",
        "- Separator: `@` - Literal `@` symbol\n",
        "- Domain: `[a-z]+` - One or more lowercase letters (e.g. `gmail` or `outlook`)\n",
        "- Dot: `\\.` - Literal dot (escaped)\n",
        "- Extension: `(?:org|net|com|io)` - Match specific extensions (e.g. `.com`, `.org`, `.io`, `.net`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import re\n",
        "\n",
        "# Match basic email format: letters@domain.extension\n",
        "email_pattern = r'[a-z]+@[a-z]+\\.(?:org|net|com|io)'\n",
        "\n",
        "df_tickets['emails'] = df_tickets['message'].apply(\n",
        "    lambda x: re.findall(email_pattern, x)\n",
        ")\n",
        "\n",
        "df_tickets[['message', 'emails']].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| message | emails |\n",
        "|---------|--------|\n",
        "| 0 | Contact me at nichole70@kemp.com or (798)034-325 to resolve this issue. | [] |\n",
        "| 1 | You can reach me by phone (970-295-1452) or email (russellbrandon@simon-rogers.org) anytime. | [] |\n",
        "| 2 | My contact details: ehamilton@silva.io and 242 844 7293. | [ehamilton@silva.io] |\n",
        "| 3 | Feel free to call 901.794.1337 or email ogarcia@howell-chavez.net for assistance. | [] |\n",
        "\n",
        "This pattern works for simple emails but misses variations with:\n",
        "\n",
        "- Other characters in the username such as numbers, dots, underscores, plus signs, or hyphens\n",
        "- Other characters in the domain such as numbers, dots, or hyphens\n",
        "- Other extensions that are not `.com`, `.org`, `.io`, or `.net`\n",
        "\n",
        "Let's expand the pattern to handle more formats:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Handle emails with numbers, dots, underscores, hyphens, plus signs\n",
        "improved_email = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}'\n",
        "\n",
        "df_tickets['emails_improved'] = df_tickets['message'].apply(\n",
        "    lambda x: re.findall(improved_email, x)\n",
        ")\n",
        "\n",
        "df_tickets[['message', 'emails_improved']].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| message | emails_improved |\n",
        "|---------|-----------------|\n",
        "| 0 | Contact me at nichole70@kemp.com or (798)034-325 to resolve this issue. | [nichole70@kemp.com] |\n",
        "| 1 | You can reach me by phone (970-295-1452) or email (russellbrandon@simon-rogers.org) anytime. | [russellbrandon@simon-rogers.org] |\n",
        "| 2 | My contact details: ehamilton@silva.io and 242 844 7293. | [ehamilton@silva.io] |\n",
        "| 3 | Feel free to call 901.794.1337 or email ogarcia@howell-chavez.net for assistance. | [ogarcia@howell-chavez.net] |\n",
        "\n",
        "The improved pattern successfully extracts all emails from the tickets! Let's move on to extracting phone numbers.\n",
        "\n",
        "### Extract Phone Numbers\n",
        "\n",
        "Common phone number formats are:\n",
        "\n",
        "- `(XXX)XXX-XXXX` - With parentheses\n",
        "- `XXX-XXX-XXXX` - Without parentheses\n",
        "- `XXX XXX XXXX` - With spaces\n",
        "- `XXX.XXX.XXXX` - With dots\n",
        "\n",
        "To handle all four phone formats, we can use the following pattern:\n",
        "\n",
        "- `\\(?` - Optional opening parenthesis\n",
        "- `\\d{3}` - Exactly 3 digits (area code)\n",
        "- `[-.\\s]?` - Optional hyphen, dot, or space\n",
        "- `\\)?` - Optional closing parenthesis\n",
        "- `\\d{3}` - Exactly 3 digits (prefix)\n",
        "- `[-.\\s]?` - Optional hyphen, dot, or space\n",
        "- `\\d{3,4}` - Exactly 3 or 4 digits\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Define phone pattern\n",
        "phone_pattern = r'\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]\\d{4}'\n",
        "\n",
        "df_tickets['phones'] = df_tickets['message'].apply(\n",
        "    lambda x: re.findall(phone_pattern, x)\n",
        ")\n",
        "\n",
        "df_tickets[['message', 'phones']].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| message | phones |\n",
        "|---------|--------|\n",
        "| 0 | Contact me at hfuentes@anderson.com or (798)034-3254 to resolve this issue. | [(798)034-3254] |\n",
        "| 1 | You can reach me by phone (702-951-4528) or email (russellbrandon@simon-rogers.org) anytime. | [(702-951-4528] |\n",
        "| 2 | My contact details: ehamilton@silva.io and 242 844 7293. | [242 844 7293] |\n",
        "| 3 | Feel free to call 901.794.1337 or email ogarcia@howell-chavez.net for assistance. | [901.794.1337] |\n",
        "\n",
        "Awesome! We are able to extract all phone numbers from the tickets!\n",
        "\n",
        "While these patterns works, they are difficult to understand and modify for someone who is not familiar with regex.\n",
        "\n",
        "> ðŸ“– Readable code reduces maintenance burden and improves team productivity. Check out [Production-Ready Data Science](https://codecut.ai/production-ready-data-science/) for detailed guidance on writing production-quality code.\n",
        "\n",
        "In the next section, we will use pregex to build more readable patterns.\n",
        "\n",
        "## pregex: Build Readable Patterns\n",
        "\n",
        "[pregex](https://github.com/manoss96/pregex) is a Python library that lets you build regex patterns using readable Python syntax instead of regex symbols. It breaks complex patterns into self-documenting components that clearly express validation logic.\n",
        "\n",
        "Install pregex:\n",
        "\n",
        "```bash\n",
        "pip install pregex\n",
        "```\n",
        "\n",
        "### Extract Email Addresses\n",
        "\n",
        "Let's extract emails using pregex's readable components.\n",
        "\n",
        "In the code, we will use the following components:\n",
        "\n",
        "- Username: `OneOrMore(AnyButWhitespace())` - Any letters but whitespace (`maria95`)\n",
        "- Separator: `@` - Literal @ symbol\n",
        "- Domain name: `OneOrMore(AnyButWhitespace())` - Any letters but whitespace (`gmail` or `outlook`)\n",
        "- Extension: `Either(\".com\", \".org\", \".io\", \".net\")` - Match specific extensions (`.com`, `.org`, `.io`, `.net`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pregex.core.classes import AnyButWhitespace\n",
        "from pregex.core.quantifiers import OneOrMore\n",
        "from pregex.core.operators import Either\n",
        "\n",
        "username = OneOrMore(AnyButWhitespace())\n",
        "at_symbol = \"@\"\n",
        "domain_name = OneOrMore(AnyButWhitespace())\n",
        "extension = Either(\".com\", \".org\", \".io\", \".net\")\n",
        "\n",
        "email_pattern = username + at_symbol + domain_name + extension\n",
        "\n",
        "# Extract emails\n",
        "df_tickets[\"emails_pregex\"] = df_tickets[\"message\"].apply(\n",
        "    lambda x: email_pattern.get_matches(x)\n",
        ")\n",
        "\n",
        "df_tickets[[\"message\", \"emails_pregex\"]].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| | message | emails_pregex |\n",
        "|---|---------|---------------|\n",
        "| 0 | Contact me at hfuentes@anderson.com or (798)034-3254 to resolve this issue. | [hfuentes@anderson.com] |\n",
        "| 1 | You can reach me by phone (702-951-4528) or email (russellbrandon@simon-rogers.org) anytime. | [(russellbrandon@simon-rogers.org] |\n",
        "| 2 | My contact details: ehamilton@silva.io and 242 844 7293. | [ehamilton@silva.io] |\n",
        "| 3 | Feel free to call 901.794.1337 or email ogarcia@howell-chavez.net for assistance. | [ogarcia@howell-chavez.net] |\n",
        "\n",
        "The output shows that we are able to extract the emails from the tickets!\n",
        "\n",
        "pregex transforms pattern matching from symbol decoding into readable code. `OneOrMore(username_chars)` communicates intent more clearly than `[a-zA-Z0-9._%+-]+`, reducing the time teammates spend understanding and modifying validation logic.\n",
        "\n",
        "\n",
        "### Extract Phone Numbers\n",
        "\n",
        "Now extract phone numbers with multiple components:\n",
        "\n",
        "- First three digits: `Optional(\"(\") + Exactly(AnyDigit(), 3) + Optional(\")\")`\n",
        "- Separator: `Either(\" \", \"-\", \".\")`\n",
        "- Second three digits: `Exactly(AnyDigit(), 3)`\n",
        "- Last four digits: `Exactly(AnyDigit(), 4)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pregex.core.classes import AnyDigit\n",
        "from pregex.core.quantifiers import Optional, Exactly\n",
        "from pregex.core.operators import Either\n",
        "\n",
        "# Build phone pattern using pregex\n",
        "first_three = Optional(\"(\") + Exactly(AnyDigit(), 3) + Optional(\")\")\n",
        "separator = Either(\" \", \"-\", \".\")\n",
        "second_three = Exactly(AnyDigit(), 3)\n",
        "last_four = Exactly(AnyDigit(), 4)\n",
        "\n",
        "phone_pattern = first_three + Optional(separator) + second_three + separator + last_four\n",
        "\n",
        "# Extract phone numbers\n",
        "df_tickets['phones_pregex'] = df_tickets['message'].apply(\n",
        "    lambda x: phone_pattern.get_matches(x)\n",
        ")\n",
        "\n",
        "df_tickets[['message', 'phones_pregex']].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| | message | phones_pregex |\n",
        "|---|---------|---------------|\n",
        "| 0 | Contact me at hfuentes@anderson.com or (798)034-3254 to resolve this issue. | [(798)034-3254] |\n",
        "| 1 | You can reach me by phone (702-951-4528) or email (russellbrandon@simon-rogers.org) anytime. | [(702-951-4528] |\n",
        "| 2 | My contact details: ehamilton@silva.io and 242 844 7293. | [242 844 7293] |\n",
        "| 3 | Feel free to call 901.794.1337 or email ogarcia@howell-chavez.net for assistance. | [901.794.1337] |\n",
        "\n",
        "\n",
        "If your system requires the raw regex pattern, you can get it with `get_compiled_pattern()`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Compiled email pattern:\", email_pattern.get_compiled_pattern().pattern)\n",
        "print(\"Compiled phone pattern:\", phone_pattern.get_compiled_pattern().pattern)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```text\n",
        "Compiled email pattern: \\S+@\\S+(?:\\.com|\\.org|\\.io|\\.net)\n",
        "Compiled phone pattern: \\(?\\d{3}\\)?(?: |-|\\.)?\\d{3}(?: |-|\\.)\\d{4}\n",
        "```\n",
        "\n",
        "> For more pregex examples including URLs and time patterns, see [PRegEx: Write Human-Readable Regular Expressions in Python](https://codecut.ai/pregex-write-human-readable-regular-expressions-in-python-2/).\n",
        "\n",
        "\n",
        "### Parse Structured Ticket Headers\n",
        "\n",
        "Now let's tackle a more complex task: parsing structured ticket headers that contain multiple fields:\n",
        "\n",
        "```text\n",
        "Ticket: 1000 | Priority: High | Assigned: John Doe # escalated\n",
        "```\n",
        "\n",
        "We will use `Capture` to extract just the values we need from each ticket:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pregex.core.quantifiers import OneOrMore\n",
        "from pregex.core.classes import AnyDigit, AnyLetter, AnyWhitespace\n",
        "from pregex.core.groups import Capture\n",
        "\n",
        "\n",
        "sample_ticket = \"Ticket: 1000 | Priority: High | Assigned: John Doe # escalated\"\n",
        "\n",
        "# Define patterns with Capture to extract just the values\n",
        "whitespace = AnyWhitespace()\n",
        "ticket_id_pattern = \"Ticket:\" + whitespace + Capture(OneOrMore(AnyDigit()))\n",
        "priority_pattern = \"Priority:\" + whitespace + Capture(OneOrMore(AnyLetter()))\n",
        "name_pattern = (\n",
        "    \"Assigned:\"\n",
        "    + whitespace\n",
        "    + Capture(OneOrMore(AnyLetter()) + \" \" + OneOrMore(AnyLetter()))\n",
        ")\n",
        "\n",
        "# Define separator pattern (whitespace around pipe)\n",
        "separator = whitespace + \"|\" + whitespace\n",
        "\n",
        "# Combine all patterns with separators\n",
        "ticket_pattern = (\n",
        "    ticket_id_pattern\n",
        "    + separator\n",
        "    + priority_pattern\n",
        "    + separator\n",
        "    + name_pattern\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, define a function to extract the ticket components from the captured components:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def get_ticket_components(ticket_string, ticket_pattern):\n",
        "    \"\"\"Extract ticket components from a ticket string.\"\"\"\n",
        "    try:\n",
        "        captures = ticket_pattern.get_captures(ticket_string)[0]\n",
        "        return pd.Series(\n",
        "            {\n",
        "                \"ticket_id\": captures[0],\n",
        "                \"priority\": captures[1],\n",
        "                \"assigned\": captures[2],\n",
        "            }\n",
        "        )\n",
        "    except IndexError:\n",
        "        return pd.Series(\n",
        "            {\"ticket_id\": None, \"priority\": None, \"assigned\": None}\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Apply the function with the pattern defined above to the sample ticket."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "components = get_ticket_components(sample_ticket, ticket_pattern)\n",
        "print(components.to_dict())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```text\n",
        "{'ticket_id': '1000', 'priority': 'High', 'assigned': 'John Doe'}\n",
        "```\n",
        "\n",
        "This looks good! Let's apply to ticket headers with inconsistent whitespace around the separators. Start by creating the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create tickets with embedded comments and variable whitespace\n",
        "tickets = [\n",
        "    \"Ticket: 1000 | Priority: High | Assigned: John Doe # escalated\",\n",
        "    \"Ticket: 1001  |  Priority: Medium  |  Assigned: Maria Garcia # team lead\",\n",
        "    \"Ticket:1002| Priority:Low |Assigned:Alice Smith # non-urgent\",\n",
        "    \"Ticket: 1003 | Priority: High | Assigned: Bob Johnson # on-call\"\n",
        "]\n",
        "\n",
        "df_tickets = pd.DataFrame({'ticket': tickets})\n",
        "df_tickets.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| ticket |\n",
        "|--------|\n",
        "| 0 | Ticket: 1000 | Priority: High | Assigned: John Doe # escalated |\n",
        "| 1 | Ticket: 1001 | Priority: Medium | Assigned: Maria Garcia # team lead |\n",
        "| 2 | Ticket:1002| Priority:Low |Assigned:Alice Smith # non-urgent |\n",
        "| 3 | Ticket: 1003 | Priority: High | Assigned: Bob Johnson # on-call |\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Extract individual components using the function\n",
        "df_pregex = df_tickets.copy()\n",
        "components_df = df_pregex[\"ticket\"].apply(get_ticket_components, ticket_pattern=ticket_pattern)\n",
        "\n",
        "df_pregex = df_pregex.assign(**components_df)\n",
        "\n",
        "df_pregex[[\"ticket_id\", \"priority\", \"assigned\"]].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| | ticket_id | priority | assigned |\n",
        "|---|-----------|----------|----------|\n",
        "| 0 | 1000 | High | John Doe |\n",
        "| 1 | None | None | None |\n",
        "| 2 | None | None | None |\n",
        "| 3 | 1003 | High | Bob Johnson |\n",
        "\n",
        "We can see that pregex misses Tickets 1 and 2 because `AnyWhitespace()` only matches a single space, while those rows use inconsistent spacing around the separators.\n",
        "\n",
        "Making pregex patterns flexible enough for variable formatting requires adding optional quantifiers to the whitespace pattern so that it can match zero or more spaces around the separators.\n",
        "\n",
        "As these fixes accumulate, pregex's readability advantage diminishes, and you end up with code that's as hard to understand as raw regex but more verbose.\n",
        "\n",
        "When parsing structured data with consistent patterns but varying details, pyparsing provides more robust handling than regex.\n",
        "\n",
        "## pyparsing: Parse Structured Ticket Headers\n",
        "\n",
        "Unlike regex's pattern matching approach, [pyparsing](https://github.com/pyparsing/pyparsing) lets you define grammar rules using Python classes, making parsing logic explicit and maintainable.\n",
        "\n",
        "Install pyparsing:\n",
        "\n",
        "```bash\n",
        "pip install pyparsing\n",
        "```\n",
        "\n",
        "Let's parse the complete structure with pyparsing, including:\n",
        "\n",
        "- Ticket ID: `Word(nums)` - One or more digits (e.g. `1000`)\n",
        "- Priority: `Word(alphas)` - One or more letters (e.g. `High`)\n",
        "- Name: `Word(alphas) + Word(alphas)` - First and last name (e.g. `John Doe`)\n",
        "\n",
        "We will also use the `pythonStyleComment` to ignore Python-style comments throughout parsing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pyparsing import Word, alphas, nums, Literal, pythonStyleComment\n",
        "\n",
        "# Define grammar components\n",
        "ticket_num = Word(nums)\n",
        "priority = Word(alphas)\n",
        "name = Word(alphas) + Word(alphas)\n",
        "\n",
        "# Define complete structure\n",
        "ticket_grammar = (\n",
        "    \"Ticket:\"\n",
        "    + ticket_num\n",
        "    + \"|\"\n",
        "    + \"Priority:\"\n",
        "    + priority\n",
        "    + \"|\"\n",
        "    + \"Assigned:\"\n",
        "    + name\n",
        ")\n",
        "\n",
        "# Automatically ignore Python-style comments throughout parsing\n",
        "ticket_grammar.ignore(pythonStyleComment)\n",
        "\n",
        "sample_ticket = \"Ticket: 1000 | Priority: High | Assigned: John Doe # escalated\"\n",
        "sample_result = ticket_grammar.parse_string(sample_ticket)\n",
        "print(sample_result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```text\n",
        "['Ticket:', '1000', '|', 'Priority:', 'High', '|', 'Assigned:', 'John', 'Doe']\n",
        "```\n",
        "\n",
        "Awesome! We are able to extract the ticket components from the ticket with a much simpler pattern!\n",
        "\n",
        "Compare this to the pregex implementation:\n",
        "\n",
        "\n",
        "```python\n",
        "ticket_pattern = (\n",
        "    \"Ticket:\" + whitespace + Capture(OneOrMore(AnyDigit()))\n",
        "    + whitespace + \"|\" + whitespace\n",
        "    + \"Priority:\" + whitespace + Capture(OneOrMore(AnyLetter()))\n",
        "    + whitespace + \"|\" + whitespace\n",
        "    + \"Assigned:\"\n",
        "    + whitespace\n",
        "    + Capture(OneOrMore(AnyLetter()) + \" \" + OneOrMore(AnyLetter()))\n",
        ")\n",
        "```\n",
        "\n",
        "We can see that pyparsing handles structured data better than pregex for the following reasons:\n",
        "\n",
        "- **No whitespace boilerplate**: pyparsing handles spacing automatically while pregex requires `+ whitespace +` between every component\n",
        "- **Self-documenting**: `Word(alphas)` clearly means \"letters\" while pregex's nested `Capture(OneOrMore(AnyLetter()))` is less readable\n",
        "\n",
        "To extract ticket components, assign names using `()` syntax and access them via dot notation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Define complete structure\n",
        "ticket_grammar = (\n",
        "    \"Ticket:\"\n",
        "    + ticket_num(\"ticket_id\")\n",
        "    + \"|\"\n",
        "    + \"Priority:\"\n",
        "    + priority(\"priority\")\n",
        "    + \"|\"\n",
        "    + \"Assigned:\"\n",
        "    + name(\"assigned\")\n",
        ")\n",
        "\n",
        "# Automatically ignore Python-style comments throughout parsing\n",
        "ticket_grammar.ignore(pythonStyleComment)\n",
        "\n",
        "sample_ticket = \"Ticket: 1000 | Priority: High | Assigned: John Doe # escalated\"\n",
        "sample_result = ticket_grammar.parse_string(sample_ticket)\n",
        "\n",
        "# Access the components by name\n",
        "print(\n",
        "    f\"Ticket ID: {sample_result.ticket_id}\",\n",
        "    f\"Priority: {sample_result.priority}\",\n",
        "    f\"Assigned: {' '.join(sample_result.assigned)}\",\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```text\n",
        "Ticket ID: 1000 Priority: High Assigned: John Doe\n",
        "```\n",
        "\n",
        "Let's apply this to the entire dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Parse all tickets and create columns\n",
        "def parse_ticket(ticket, ticket_grammar):\n",
        "    result = ticket_grammar.parse_string(ticket)\n",
        "    return pd.Series(\n",
        "        {\n",
        "            \"ticket_id\": result.ticket_id,\n",
        "            \"priority\": result.priority,\n",
        "            \"assigned\": \" \".join(result.assigned),\n",
        "        }\n",
        "    )\n",
        "\n",
        "\n",
        "df_pyparsing = df_tickets.copy()\n",
        "components_df_pyparsing = df_pyparsing[\"ticket\"].apply(parse_ticket, ticket_grammar=ticket_grammar)\n",
        "df_pyparsing = df_pyparsing.assign(**components_df_pyparsing)\n",
        "\n",
        "df_pyparsing[[\"ticket_id\", \"priority\", \"assigned\"]].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| | ticket_id | priority | assigned |\n",
        "|---|-----------|----------|----------|\n",
        "| 0 | 1000 | High | John Doe |\n",
        "| 1 | 1001 | Medium | Maria Garcia |\n",
        "| 2 | 1002 | Low | Alice Smith |\n",
        "| 3 | 1003 | High | Bob Johnson |\n",
        "\n",
        "The output looks good!\n",
        "\n",
        "Let's try to parse some more structured data with pyparsing.\n",
        "\n",
        "### Extract Code Blocks from Markdown\n",
        "\n",
        "Use `SkipTo` to extract Python code between code block markers without complex regex patterns like `r'```python(.*?)```'`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pyparsing import Literal, SkipTo\n",
        "\n",
        "code_start = Literal(\"```python\")\n",
        "code_end = Literal(\"```\")\n",
        "\n",
        "code_block = code_start + SkipTo(code_end)(\"code\") + code_end\n",
        "\n",
        "markdown = \"\"\"```python\n",
        "def hello():\n",
        "    print(\"world\")\n",
        "```\"\"\"\n",
        "\n",
        "result = code_block.parse_string(markdown)\n",
        "print(result.code)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```text\n",
        "def hello():\n",
        "    print(\"world\")\n",
        "```\n",
        "\n",
        "### Parse Nested Structures\n",
        "\n",
        "`nested_expr` handles arbitrary nesting depth, which regex fundamentally cannot parse:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pyparsing import nested_expr\n",
        "\n",
        "# Default: parentheses\n",
        "nested_list = nested_expr()\n",
        "result = nested_list.parse_string(\"((2 + 3) * (4 - 1))\")\n",
        "print(result.as_list())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```text\n",
        "[[['2', '+', '3'], '*', ['4', '-', '1']]]\n",
        "```\n",
        "\n",
        "\n",
        "## Related Tutorials\n",
        "\n",
        "Here are some related text processing tools:\n",
        "\n",
        "- **Text similarity matching**: [4 Text Similarity Tools: When Regex Isn't Enough](https://codecut.ai/text-similarity-fuzzy-matching-guide/) compares regex preprocessing, difflib, RapidFuzz, and Sentence Transformers for matching product names and handling data variations\n",
        "- **Business entity extraction**: [langextract vs spaCy: AI-Powered vs Rule-Based Entity Extraction](https://codecut.ai/langextract-vs-spacy-entity-extraction-comparison/) evaluates regex, spaCy, GLiNER, and langextract for extracting structured information from financial documents"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}