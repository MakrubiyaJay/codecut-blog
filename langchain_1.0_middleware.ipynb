{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Installation {#installation}\n",
        "\n",
        "Install LangChain 1.0 and the OpenAI integration:\n",
        "\n",
        "```bash\n",
        "# Option 1: pip\n",
        "pip install langchain langchain-openai\n",
        "\n",
        "# Option 2: uv (faster alternative to pip)\n",
        "uv add langchain langchain-openai\n",
        "```\n",
        "\n",
        "> **Note**: If you're upgrading from LangChain v0.x, add the `--U` flag: `pip install --U langchain langchain-openai`\n",
        "\n",
        "You'll also need an [OpenAI API key](https://platform.openai.com/api-keys):\n",
        "\n",
        "```bash\n",
        "export OPENAI_API_KEY=\"your-api-key-here\"\n",
        "```\n",
        "\n",
        "## Message Summarization {#message-summarization}\n",
        "\n",
        "When building conversational agents, message history grows with each turn. Long conversations quickly exceed model context windows, causing API errors or degraded performance.\n",
        "\n",
        "`SummarizationMiddleware` automates this by:\n",
        "\n",
        "- Monitoring token count across the conversation\n",
        "- Condensing older messages when thresholds are exceeded\n",
        "- Preserving recent context for immediate relevance\n",
        "\n",
        "The benefits:\n",
        "\n",
        "- **Reduced API costs** from sending fewer tokens per request\n",
        "- **Faster responses** with smaller context windows\n",
        "- **Complete context** through summaries plus full recent history\n",
        "\n",
        "Here's how to use `SummarizationMiddleware` as part of an agent:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from langchain.agents import create_agent\n",
        "from langchain.agents.middleware import SummarizationMiddleware\n",
        "\n",
        "agent = create_agent(\n",
        "    model=\"openai:gpt-4o\",\n",
        "    tools=[],\n",
        "    middleware=[\n",
        "        SummarizationMiddleware(\n",
        "            model=\"openai:gpt-4o-mini\",\n",
        "            max_tokens_before_summary=400,\n",
        "            messages_to_keep=5\n",
        "        )\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This configuration sets up automatic conversation management:\n",
        "\n",
        "- `model=\"openai:gpt-4o\"` - The primary model for agent responses\n",
        "- `max_tokens_before_summary=400` - Triggers summarization when conversation exceeds 400 tokens\n",
        "- `messages_to_keep=5` - Preserves the 5 most recent messages in full\n",
        "- `model=\"openai:gpt-4o-mini\"` - Uses a faster, cheaper model for creating summaries\n",
        "\n",
        "> **Note**: These configuration values are set low for demonstration purposes to quickly show summarization behavior. Production applications typically use `max_tokens_before_summary=4000` and `messages_to_keep=20` (the recommended defaults).\n",
        "\n",
        "Let's use this agent to simulate a customer support conversation and track token usage.\n",
        "\n",
        "First, let's set up a realistic customer support conversation with multiple turns:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Simulate a customer support conversation\n",
        "conversation_turns = [\n",
        "    \"I ordered a laptop last week but haven't received it yet. Order #12345.\",\n",
        "    \"Can you check the shipping status? I need it for work next Monday.\",\n",
        "    \"Also, I originally wanted the 16GB RAM model but ordered 8GB by mistake.\",\n",
        "    \"Is it too late to change the order? Or should I return and reorder?\",\n",
        "    \"What's your return policy on laptops? Do I need the original packaging?\",\n",
        "    \"If I return it, how long does the refund take to process?\",\n",
        "    \"Can I get expedited shipping on the replacement 16GB model?\",\n",
        "    \"Does the 16GB version come with the same warranty as the 8GB?\",\n",
        "    \"Are there any promotional codes I can use for the new order?\",\n",
        "    \"What if the new laptop arrives damaged? What's the process?\",\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, define helper functions to track token usage and verify summarization:\n",
        "\n",
        "- **`estimate_token_count()`**: Calculates approximate tokens by counting words in all messages\n",
        "- **`get_actual_tokens()`**: Extracts the actual token count from the model's response metadata\n",
        "- **`print_token_comparison()`**: Displays estimated vs actual tokens to show when summarization occurs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def estimate_token_count(messages):\n",
        "    \"\"\"Estimate total tokens in message history.\"\"\"\n",
        "    return sum(len(msg.content.split()) * 1.3 for msg in messages)\n",
        "\n",
        "def get_actual_tokens(response):\n",
        "    \"\"\"Extract actual token count from response metadata.\"\"\"\n",
        "    last_ai_message = response[\"messages\"][-1]\n",
        "    if hasattr(last_ai_message, 'usage_metadata') and last_ai_message.usage_metadata:\n",
        "        return last_ai_message.usage_metadata.get(\"input_tokens\", 0)\n",
        "    return None\n",
        "\n",
        "def print_token_comparison(turn_number, estimated, actual):\n",
        "    \"\"\"Print token count comparison for a conversation turn.\"\"\"\n",
        "    if actual is not None:\n",
        "        print(f\"Turn {turn_number}: ~{int(estimated)} tokens (estimated) â†’ {actual} tokens (actual)\")\n",
        "    else:\n",
        "        print(f\"Turn {turn_number}: ~{int(estimated)} tokens (estimated)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, run the conversation and observe token usage across turns:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "messages = []\n",
        "for i, question in enumerate(conversation_turns, 1):\n",
        "    messages.append(HumanMessage(content=question))\n",
        "\n",
        "    estimated_tokens = estimate_token_count(messages)\n",
        "    response = agent.invoke({\"messages\": messages})\n",
        "    messages.extend(response[\"messages\"][len(messages):])\n",
        "\n",
        "    actual_tokens = get_actual_tokens(response)\n",
        "    print_token_comparison(i, estimated_tokens, actual_tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Output:\n",
        "\n",
        "```text\n",
        "Turn 1: ~16 tokens (estimated) â†’ 24 tokens (actual)\n",
        "Turn 2: ~221 tokens (estimated) â†’ 221 tokens (actual)\n",
        "Turn 3: ~408 tokens (estimated) â†’ 415 tokens (actual)\n",
        "Turn 4: ~646 tokens (estimated) â†’ 509 tokens (actual)\n",
        "Turn 5: ~661 tokens (estimated) â†’ 524 tokens (actual)\n",
        "Turn 6: ~677 tokens (estimated) â†’ 379 tokens (actual)\n",
        "Turn 7: ~690 tokens (estimated) â†’ 347 tokens (actual)\n",
        "Turn 8: ~705 tokens (estimated) â†’ 184 tokens (actual)\n",
        "Turn 9: ~721 tokens (estimated) â†’ 204 tokens (actual)\n",
        "Turn 10: ~734 tokens (estimated) â†’ 195 tokens (actual)\n",
        "```\n",
        "\n",
        "Notice the pattern in the token counts:\n",
        "\n",
        "- **Turns 1-3**: Tokens grow steadily (24 â†’ 221 â†’ 415) as the conversation builds\n",
        "- **Turn 4**: Summarization kicks in with actual tokens dropping to 509 despite 646 estimated\n",
        "- **Turn 8**: Most dramatic reduction with only 184 actual tokens sent vs 705 estimated (74% reduction!)\n",
        "\n",
        "Once past the 400-token threshold, the middleware automatically condenses older messages while preserving the 5 most recent turns. This keeps token usage low even as the conversation continues.\n",
        "\n",
        "## PII Detection and Filtering {#pii-detection-and-filtering}\n",
        "\n",
        "Customer support conversations often contain sensitive information like email addresses, phone numbers, and account IDs. Logging or storing this data without redaction creates compliance and security risks.\n",
        "\n",
        "`PIIMiddleware` automatically protects personally identifiable information (PII) by:\n",
        "\n",
        "- Built-in detectors for common PII types (email, credit cards, IP addresses)\n",
        "- Custom regex patterns for domain-specific sensitive data\n",
        "- Multiple protection strategies: redact, mask, hash, or block\n",
        "- Automatic application to all messages before model processing\n",
        "\n",
        "First, configure the agent with multiple PII detectors:\n",
        "\n",
        "Each detector in this example demonstrates a different protection strategy:\n",
        "\n",
        "- **Email detector**: Uses built-in pattern with `redact` strategy (complete replacement)\n",
        "- **Phone detector**: Uses custom regex `\\b\\d{3}-\\d{3}-\\d{4}\\b` with `mask` strategy (partial visibility)\n",
        "- **Account ID detector**: Uses custom pattern `\\b[A-Z]{2}\\d{8}\\b` with `redact` strategy (complete removal)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from langchain.agents import create_agent\n",
        "from langchain.agents.middleware import PIIMiddleware\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "agent = create_agent(\n",
        "    model=\"openai:gpt-4o\",\n",
        "    tools=[],\n",
        "    middleware=[\n",
        "        # Built-in email detector - replaces emails with [REDACTED_EMAIL]\n",
        "        PIIMiddleware(\"email\", strategy=\"redact\", apply_to_input=True),\n",
        "        # Custom phone number pattern - shows only last 4 digits\n",
        "        PIIMiddleware(\n",
        "            \"phone\",\n",
        "            detector=r\"\\b\\d{3}-\\d{3}-\\d{4}\\b\",\n",
        "            strategy=\"mask\",\n",
        "            apply_to_input=True,\n",
        "        ),\n",
        "        # Custom regex pattern for account IDs (e.g., AB12345678)\n",
        "        PIIMiddleware(\n",
        "            \"account_id\",\n",
        "            detector=r\"\\b[A-Z]{2}\\d{8}\\b\",\n",
        "            strategy=\"redact\",\n",
        "            apply_to_input=True,\n",
        "        ),\n",
        "    ],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, create a message containing sensitive information and invoke the agent:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create a message with PII\n",
        "original_message = HumanMessage(content=\"My email is john@example.com, phone is 555-123-4567, and account is AB12345678\")\n",
        "print(f\"Original message: {original_message.content}\")\n",
        "\n",
        "# Invoke the agent\n",
        "response = agent.invoke({\"messages\": [original_message]})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Output:\n",
        "\n",
        "```text\n",
        "Original message: My email is john@example.com, phone is 555-123-4567, and account is AB12345678\n",
        "```\n",
        "\n",
        "Finally, inspect the message that was actually sent to the model to verify redaction:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Check what was actually sent to the model (after PII redaction)\n",
        "input_message = response[\"messages\"][0]\n",
        "print(f\"Message sent to model: {input_message.content}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Output:\n",
        "\n",
        "```text\n",
        "Message sent to model: My email is [REDACTED_EMAIL], phone is ****4567, and account is [REDACTED_ACCOUNT_ID]\n",
        "```\n",
        "\n",
        "The middleware successfully processed all three types of sensitive information:\n",
        "\n",
        "- **Email**: Completely redacted to `[REDACTED_EMAIL]`\n",
        "- **Phone**: Masked to show only last 4 digits (`****4567`)\n",
        "- **Account ID**: Completely redacted to `[REDACTED_ACCOUNT_ID]`\n",
        "\n",
        "\n",
        "## Human-in-the-Loop {#human-in-the-loop}\n",
        "\n",
        "Autonomous agents can perform sensitive actions like processing refunds or modifying account settings. Executing these without human oversight creates risk of errors or abuse.\n",
        "\n",
        "`HumanInTheLoopMiddleware` automates approval workflows by pausing execution and waiting for approval before proceeding:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from langchain.agents import create_agent\n",
        "from langchain.agents.middleware import HumanInTheLoopMiddleware\n",
        "from langchain_core.tools import tool\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "\n",
        "@tool\n",
        "def process_refund(amount: float, reason: str) -> str:\n",
        "    \"\"\"Process a customer refund. Use this when a customer requests a refund.\"\"\"\n",
        "    return f\"Refund of ${amount} processed for reason: {reason}\"\n",
        "\n",
        "\n",
        "# Create memory checkpointer for state persistence\n",
        "memory = MemorySaver()\n",
        "\n",
        "agent = create_agent(\n",
        "    model=\"openai:gpt-4o\",\n",
        "    tools=[process_refund],\n",
        "    middleware=[HumanInTheLoopMiddleware(interrupt_on={\"process_refund\": True})],\n",
        "    checkpointer=memory,  # Required for state persistence\n",
        "    system_prompt=\"You are a customer support agent. Use the available tools to help customers. When a customer asks for a refund, use the process_refund tool.\",\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This configuration sets up an agent that:\n",
        "\n",
        "- Uses `HumanInTheLoopMiddleware` to pause execution before calling `process_refund`\n",
        "- Uses a checkpointer (`MemorySaver`) to save agent state during interruptions, allowing execution to resume after approval\n",
        "\n",
        "Now let's invoke the agent with a refund request:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Agent pauses before executing sensitive tools\n",
        "response = agent.invoke(\n",
        "    {\"messages\": [(\"user\", \"I need a refund of $100 for my damaged laptop\")]},\n",
        "    config={\"configurable\": {\"thread_id\": \"user-123\"}},\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The agent will pause when it tries to process the refund. To verify this happened, let's define helper functions for interrupt detection."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def has_interrupt(response):\n",
        "    \"\"\"Check if response contains an interrupt.\"\"\"\n",
        "    return \"__interrupt__\" in response\n",
        "\n",
        "def display_action(action):\n",
        "    \"\"\"Display pending action details.\"\"\"\n",
        "    print(f\"Pending action: {action['name']}\")\n",
        "    print(f\"Arguments: {action['args']}\")\n",
        "    print()\n",
        "\n",
        "def get_user_approval():\n",
        "    \"\"\"Prompt user for approval and return decision.\"\"\"\n",
        "    approval = input(\"Approve this action? (yes/no): \")\n",
        "    if approval.lower() == \"yes\":\n",
        "        print(\"âœ“ Action approved\")\n",
        "        return True\n",
        "    else:\n",
        "        print(\"âœ— Action rejected\")\n",
        "        return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now use these helpers to check for interrupts and process approval:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "if has_interrupt(response):\n",
        "    print(\"Execution interrupted - waiting for approval\\n\")\n",
        "\n",
        "    interrupts = response[\"__interrupt__\"]\n",
        "    for interrupt in interrupts:\n",
        "        for action in interrupt.value[\"action_requests\"]:\n",
        "            display_action(action)\n",
        "            approved = get_user_approval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Output:\n",
        "\n",
        "```text\n",
        "Execution interrupted - waiting for approval\n",
        "\n",
        "Pending action: process_refund\n",
        "Arguments: {'amount': 100, 'reason': 'Damaged Laptop'}\n",
        "\n",
        "Approve this action? (yes/no): yes\n",
        "âœ“ Action approved\n",
        "```\n",
        "\n",
        "The middleware successfully intercepted the `process_refund` tool call before execution, displaying all necessary details (action name and arguments) for human review. Only after explicit approval does the agent proceed with the sensitive operation.\n",
        "\n",
        "## Task Planning {#task-planning}\n",
        "\n",
        "Complex tasks like \"refactor my codebase\" or \"analyze this dataset\" require breaking down into smaller, manageable steps. Without explicit planning, agents often might jump between subtasks randomly or skip critical steps entirely.\n",
        "\n",
        "`TodoListMiddleware` enables structured task management by:\n",
        "\n",
        "- Automatically providing a `write_todos` tool for task planning\n",
        "- Tracking completion status across multi-step workflows\n",
        "- Returning structured todo items in agent results\n",
        "\n",
        "The benefits:\n",
        "\n",
        "- **Better task decomposition** through explicit step-by-step planning\n",
        "- **Progress tracking** to monitor complex workflow completion\n",
        "- **Reduced errors** from skipped or forgotten subtasks\n",
        "\n",
        "Here's how to enable planning for an agent:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from langchain.agents import create_agent\n",
        "from langchain.agents.middleware import TodoListMiddleware\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def analyze_code(file_path: str) -> str:\n",
        "    \"\"\"Analyze code quality and find issues.\"\"\"\n",
        "    return f\"Analyzed {file_path}: Found 3 code smells, 2 security issues\"\n",
        "\n",
        "@tool\n",
        "def refactor_code(file_path: str, changes: str) -> str:\n",
        "    \"\"\"Refactor code with specified changes.\"\"\"\n",
        "    return f\"Refactored {file_path}: {changes}\"\n",
        "\n",
        "agent = create_agent(\n",
        "    model=\"openai:gpt-4o\",\n",
        "    tools=[analyze_code, refactor_code],\n",
        "    middleware=[TodoListMiddleware()]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This configuration automatically injects planning capabilities into the agent.\n",
        "\n",
        "Now let's ask the agent to perform a multi-step refactoring task:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "response = agent.invoke({\n",
        "    \"messages\": [HumanMessage(\"I need to refactor my authentication module. First analyze it, then suggest improvements, and finally implement the changes.\")]\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check the agent's todo list to see how it planned the work:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Access the structured todo list from the response\n",
        "if \"todos\" in response:\n",
        "    print(\"Agent's Task Plan:\")\n",
        "    for i, todo in enumerate(response[\"todos\"], 1):\n",
        "        status = todo.get(\"status\", \"pending\")\n",
        "        print(f\"{i}. [{status}] {todo['content']}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Output:\n",
        "\n",
        "```text\n",
        "Agent's Task Plan:\n",
        "1. [in_progress] Analyze the authentication module code to identify quality issues and areas for improvement.\n",
        "2. [pending] Suggest improvements based on the analysis of the authentication module.\n",
        "3. [pending] Implement the suggested improvements in the authentication module code.\n",
        "```\n",
        "\n",
        "Nice! The agent automatically decomposed the multi-step refactoring request into 3 distinct tasks, with 1 in progress and 2 pending. This structured approach ensures systematic execution without skipping critical steps.\n",
        "\n",
        "## Intelligent Tool Selection {#intelligent-tool-selection}\n",
        "\n",
        "Agents with many tools (10+) face a scaling problem: sending all tool descriptions with every request wastes tokens and degrades performance. The model must process irrelevant options, increasing latency and cost.\n",
        "\n",
        "`LLMToolSelectorMiddleware` solves this by using a smaller model to pre-filter relevant tools:\n",
        "\n",
        "- Uses a secondary LLM (separate from the main agent model) to pre-filter and limit tools sent to main model\n",
        "- Allows critical tools to always be included in selection\n",
        "- Analyzes queries to select only relevant tools\n",
        "\n",
        "The benefits:\n",
        "\n",
        "- **Lower costs** from sending fewer tool descriptions per request\n",
        "- **Faster responses** with smaller tool context\n",
        "- **Better accuracy** when model isn't distracted by irrelevant options\n",
        "\n",
        "Let's create an agent with many tools for a customer support scenario:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from langchain.agents import create_agent\n",
        "from langchain.agents.middleware import LLMToolSelectorMiddleware\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "# Define multiple tools for different support scenarios\n",
        "@tool\n",
        "def lookup_order(order_id: str) -> str:\n",
        "    \"\"\"Look up order details and shipping status.\"\"\"\n",
        "    return f\"Order {order_id}: Shipped on 2025-01-15\"\n",
        "\n",
        "@tool\n",
        "def process_refund(order_id: str, amount: float) -> str:\n",
        "    \"\"\"Process a customer refund.\"\"\"\n",
        "    return f\"Refund of ${amount} processed for order {order_id}\"\n",
        "\n",
        "@tool\n",
        "def check_inventory(product_id: str) -> str:\n",
        "    \"\"\"Check product inventory levels.\"\"\"\n",
        "    return f\"Product {product_id}: 42 units in stock\"\n",
        "\n",
        "@tool\n",
        "def update_address(order_id: str, new_address: str) -> str:\n",
        "    \"\"\"Update shipping address for an order.\"\"\"\n",
        "    return f\"Address updated for order {order_id}\"\n",
        "\n",
        "@tool\n",
        "def cancel_order(order_id: str) -> str:\n",
        "    \"\"\"Cancel an existing order.\"\"\"\n",
        "    return f\"Order {order_id} cancelled\"\n",
        "\n",
        "@tool\n",
        "def track_shipment(tracking_number: str) -> str:\n",
        "    \"\"\"Track package location.\"\"\"\n",
        "    return f\"Package {tracking_number}: Out for delivery\"\n",
        "\n",
        "@tool\n",
        "def apply_discount(order_id: str, code: str) -> str:\n",
        "    \"\"\"Apply discount code to order.\"\"\"\n",
        "    return f\"Discount {code} applied to order {order_id}\"\n",
        "\n",
        "@tool\n",
        "def schedule_delivery(order_id: str, date: str) -> str:\n",
        "    \"\"\"Schedule delivery for specific date.\"\"\"\n",
        "    return f\"Delivery scheduled for {date}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Configure the agent with intelligent tool selection:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "agent = create_agent(\n",
        "    model=\"openai:gpt-4o\",\n",
        "    tools=[\n",
        "        lookup_order, process_refund, check_inventory,\n",
        "        update_address, cancel_order, track_shipment,\n",
        "        apply_discount, schedule_delivery\n",
        "    ],\n",
        "    middleware=[\n",
        "        LLMToolSelectorMiddleware(\n",
        "            model=\"openai:gpt-4o-mini\",  # Use cheaper model for selection\n",
        "            max_tools=3,  # Limit to 3 most relevant tools\n",
        "            always_include=[\"lookup_order\"],  # Always include order lookup\n",
        "        )\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This configuration creates an efficient filtering system:\n",
        "\n",
        "- `model=\"openai:gpt-4o-mini\"` - Uses a smaller, faster model for tool selection\n",
        "- `max_tools=3` - Limits to 3 most relevant tools per query\n",
        "- `always_include=[\"lookup_order\"]` - Ensures order lookup is always available\n",
        "\n",
        "Now test the agent with different customer requests:\n",
        "\n",
        "First, define a helper function to display tool usage:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def show_tools_used(response):\n",
        "    \"\"\"Display which tools were called during agent execution.\"\"\"\n",
        "    tools_used = []\n",
        "    for msg in response[\"messages\"]:\n",
        "        if hasattr(msg, \"tool_calls\") and msg.tool_calls:\n",
        "            for tool_call in msg.tool_calls:\n",
        "                tools_used.append(tool_call[\"name\"])\n",
        "\n",
        "    if tools_used:\n",
        "        print(f\"Tools used: {', '.join(tools_used)}\")\n",
        "    print(f\"Response: {response['messages'][-1].content}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test with a package tracking query:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Example 1: Package tracking query\n",
        "response = agent.invoke({\n",
        "    \"messages\": [HumanMessage(\"Where is my package? Tracking number is 1Z999AA10123456784\")]\n",
        "})\n",
        "show_tools_used(response)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Output:\n",
        "\n",
        "```text\n",
        "Tools used: track_shipment\n",
        "Response: Your package with tracking number 1Z999AA10123456784 is currently out for delivery.\n",
        "```\n",
        "\n",
        "Test with a refund request:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Example 2: Refund request\n",
        "response = agent.invoke({\n",
        "    \"messages\": [HumanMessage(\"I need a refund of $50 for order ORD-12345\")]\n",
        "})\n",
        "show_tools_used(response)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Output:\n",
        "\n",
        "```text\n",
        "Tools used: lookup_order, process_refund\n",
        "Response: The refund of $50 for order ORD-12345 has been successfully processed.\n",
        "\n",
        "```\n",
        "\n",
        "Test with an inventory check:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Example 3: Inventory check\n",
        "response = agent.invoke({\n",
        "    \"messages\": [HumanMessage(\"Do you have product SKU-789 in stock?\")]\n",
        "})\n",
        "show_tools_used(response)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Output:\n",
        "\n",
        "```text\n",
        "Tools used: check_inventory\n",
        "Response: Yes, we currently have 42 units of product SKU-789 in stock.\n",
        "```\n",
        "\n",
        "The middleware demonstrated precise tool selection across different query types:\n",
        "\n",
        "- `track_shipment` for tracking numbers\n",
        "- `lookup_order` + `process_refund` for refund requests\n",
        "- `check_inventory` for stock queries\n",
        "\n",
        "Each request filtered out 5+ irrelevant tools, sending only what was needed to the main model.\n",
        "\n",
        "## Building a Production Agent with Multiple Middleware {#building-a-production-agent-with-multiple-middleware}\n",
        "\n",
        "Let's combine three middleware components to build a production-ready customer support agent that handles a realistic scenario: a customer with a long conversation history requesting a refund and sharing their email address."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from langchain.agents import create_agent\n",
        "from langchain.agents.middleware import (\n",
        "    SummarizationMiddleware,\n",
        "    PIIMiddleware,\n",
        "    HumanInTheLoopMiddleware\n",
        ")\n",
        "from langchain_core.tools import tool\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "@tool\n",
        "def process_refund(amount: float, reason: str) -> str:\n",
        "    \"\"\"Process a customer refund.\"\"\"\n",
        "    return f\"Refund of ${amount} processed for reason: {reason}\"\n",
        "\n",
        "# Create agent with three middleware components\n",
        "agent = create_agent(\n",
        "    model=\"openai:gpt-4o\",\n",
        "    tools=[process_refund],\n",
        "    middleware=[\n",
        "        SummarizationMiddleware(\n",
        "            model=\"openai:gpt-4o-mini\",\n",
        "            max_tokens_before_summary=400,\n",
        "            messages_to_keep=5\n",
        "        ),\n",
        "        PIIMiddleware(\"email\", strategy=\"redact\", apply_to_input=True),\n",
        "        HumanInTheLoopMiddleware(interrupt_on={\"process_refund\": True})\n",
        "    ],\n",
        "    checkpointer=MemorySaver()\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now test with a realistic customer interaction, processing each message to show how middleware handles them.\n",
        "\n",
        "First, define a helper function to track middleware behavior using the helper functions defined earlier:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def process_message_with_tracking(agent, messages, thread_id, turn_num):\n",
        "    \"\"\"Process messages and show middleware behavior.\"\"\"\n",
        "    print(f\"\\n--- Turn {turn_num} ---\")\n",
        "    print(f\"User: {messages[-1][1]}\")\n",
        "\n",
        "    response = agent.invoke(\n",
        "        {\"messages\": messages},\n",
        "        config={\"configurable\": {\"thread_id\": thread_id}}\n",
        "    )\n",
        "\n",
        "    # Check for interrupts (human-in-the-loop)\n",
        "    if has_interrupt(response):\n",
        "        print(\"â¸ Execution paused for approval\")\n",
        "    else:\n",
        "        # Show agent response\n",
        "        agent_message = response[\"messages\"][-1].content\n",
        "        print(f\"Agent: {agent_message}\")\n",
        "\n",
        "    # Check for PII redaction\n",
        "    full_response = str(response[\"messages\"])\n",
        "    if \"[REDACTED_EMAIL]\" in full_response:\n",
        "        print(\"ðŸ”’ PII detected and redacted\")\n",
        "\n",
        "    return response"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now simulate a customer conversation that demonstrates all three middleware components:\n",
        "\n",
        "- **Turns 1-3**: Normal conversation flow about a damaged laptop\n",
        "- **Turn 4**: Customer shares email and asks for confirmation (tests PIIMiddleware redaction)\n",
        "- **Turn 5**: Customer requests $1200 refund (triggers HumanInTheLoopMiddleware approval)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "messages = []\n",
        "\n",
        "# Turn 1: Initial complaint\n",
        "messages.append((\"user\", \"I ordered a laptop but it arrived damaged.\"))\n",
        "process_message_with_tracking(agent, messages, \"customer-456\", 1)\n",
        "\n",
        "# Turn 2: Additional details\n",
        "messages.append((\"user\", \"I already tried troubleshooting but it won't turn on.\"))\n",
        "process_message_with_tracking(agent, messages, \"customer-456\", 2)\n",
        "\n",
        "# Turn 3: More context\n",
        "messages.append((\"user\", \"The screen is cracked and there's a dent on the corner.\"))\n",
        "process_message_with_tracking(agent, messages, \"customer-456\", 3)\n",
        "\n",
        "# Turn 4: PII exposure - test if middleware hides email from model\n",
        "messages.append((\"user\", \"My email is customer@example.com. Can you confirm my email address?\"))\n",
        "response = process_message_with_tracking(agent, messages, \"customer-456\", 4)\n",
        "\n",
        "# Turn 5: Sensitive action request - triggers human approval\n",
        "messages.append((\"user\", \"Can I get a full refund of $1200?\"))\n",
        "response = process_message_with_tracking(agent, messages, \"customer-456\", 5)\n",
        "\n",
        "# If interrupted, show approval flow\n",
        "if has_interrupt(response):\n",
        "    interrupts = response[\"__interrupt__\"]\n",
        "    for interrupt in interrupts:\n",
        "        for action in interrupt.value[\"action_requests\"]:\n",
        "            display_action(action)\n",
        "            approved = get_user_approval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Output:\n",
        "\n",
        "```text\n",
        "--- Turn 1 ---\n",
        "User: I ordered a laptop but it arrived damaged.\n",
        "Agent: I'm sorry to hear that your laptop arrived damaged. To resolve this issue, I can assist you in processing a refund. Could you please provide the amount of the purchase and any specific reason you would like to include for the refund?\n",
        "\n",
        "--- Turn 2 ---\n",
        "User: I already tried troubleshooting but it won't turn on.\n",
        "Agent: Thank you for sharing that information. I'll proceed with processing a refund for the damaged laptop. Could you please provide the purchase amount, so I can include it in the refund request?\n",
        "\n",
        "--- Turn 3 ---\n",
        "User: The screen is cracked and there's a dent on the corner.\n",
        "Agent: I'm sorry to hear about the condition of your laptop. I will help you process a refund. Could you please let me know the purchase amount, so I can proceed with the refund request?\n",
        "\n",
        "--- Turn 4 ---\n",
        "User: My email is customer@example.com. Can you confirm my email address?\n",
        "Agent: I'm sorry, but I'm unable to confirm or access email addresses for privacy and security reasons. However, I can assist you with processing a refund. Could you please provide the amount you paid for the laptop so that I can proceed with the refund request?\n",
        "ðŸ”’ PII detected and redacted\n",
        "\n",
        "--- Turn 5 ---\n",
        "User: Can I get a full refund of $1200?\n",
        "â¸ Execution paused for approval\n",
        "\n",
        "Pending action: process_refund\n",
        "Arguments: {'amount': 1200, 'reason': 'Laptop arrived damaged with a cracked screen and dent on the corner, and it will not turn on after troubleshooting.'}\n",
        "\n",
        "Approve this action? (yes/no): yes\n",
        "âœ“ Action approved\n",
        "```\n",
        "\n",
        "The output demonstrates proper security controls:\n",
        "\n",
        "- **Turn 4**: Agent states it \"cannot confirm or access email addresses,\" confirming PIIMiddleware successfully redacted `customer@example.com` to `[REDACTED_EMAIL]`\n",
        "- **Email protection**: Model never saw the actual address, preventing data leaks or logging\n",
        "- **Refund approval**: $1200 transaction didn't execute until human approval was granted\n",
        "\n",
        "> For coordinating multiple agents with shared state and workflows, explore our [LangGraph tutorial](https://codecut.ai/building-multi-agent-ai-langgraph-tutorial/).\n",
        "\n",
        "## Related Tutorials\n",
        "\n",
        "- **Structured Outputs**: [Enforce Structured Outputs from LLMs with PydanticAI](https://codecut.ai/enforce-structured-outputs-from-llms-with-pydanticai/) for type-safe agent responses\n",
        "- **RAG Implementation**: [Build a Complete RAG System with 5 Open-Source Tools](https://codecut.ai/open-source-rag-pipeline-intelligent-qa-system/) for question-answering agents\n",
        "- **Vector Storage**: [Implement Semantic Search in Postgres Using pgvector and Ollama](https://codecut.ai/semantic-search-postgres-pgvector-ollama/) for production-grade embedding storage"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}