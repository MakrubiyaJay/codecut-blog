{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Text Preprocessing with regex\n",
        "\n",
        "> ðŸ“– Read the full article: [4 Text Similarity Tools: When Regex Isn''t Enough](https://codecut.ai/text-similarity-fuzzy-matching-guide/)\n",
        "\n",
        "\n",
        "Raw text data contains special characters, inconsistent capitalization, and formatting variations. Regular expressions provide the first line of defense by normalizing text.\n",
        "\n",
        "These pattern-matching tools, accessed through Python's `re` module, excel at finding and replacing text patterns like symbols, whitespace, and formatting inconsistencies.\n",
        "\n",
        "Let's start with a realistic dataset that demonstrates common text similarity challenges:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import re\n",
        "\n",
        "\n",
        "# Sample messy text data\n",
        "messy_products = [\n",
        "    \"iPhoneÂ® 14 Pro Max\",\n",
        "    \"IPHONE 14 pro max\",\n",
        "    \"Apple iPhone 14 Pro Max 256GB\",\n",
        "    \"iPhone14ProMax\",\n",
        "    \"i-Phone 14 Pro Max\",\n",
        "    \"Samsung Galaxy S23 Ultra\",\n",
        "    \"SAMSUNG Galaxy S23 Ultra 5G\",\n",
        "    \"Galaxy S23 Ultra (512GB)\",\n",
        "    \"Samsung S23 Ultra\",\n",
        "    \"wireless headphones\",\n",
        "    \"bluetooth earbuds\",\n",
        "    \"Sony WH-1000XM4 Headphones\",\n",
        "    \"WH-1000XM4 Wireless Headphones\",\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With our test data established, we can build a comprehensive preprocessing function to handle these variations:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def preprocess_product_name(text):\n",
        "    \"\"\"Clean product names for better similarity matching.\"\"\"\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove special characters and symbols\n",
        "    text = re.sub(r\"[Â®â„¢Â©]\", \"\", text)\n",
        "    text = re.sub(r\"[^\\w\\s-]\", \" \", text)\n",
        "\n",
        "    # Normalize spaces and hyphens\n",
        "    text = re.sub(r\"[-_]+\", \" \", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "\n",
        "    # Remove size/capacity info in parentheses\n",
        "    text = re.sub(r\"\\([^)]*\\)\", \"\", text)\n",
        "\n",
        "    return text.strip()\n",
        "\n",
        "> ðŸ“– **Related**: These regex patterns use traditional syntax for maximum compatibility. For more readable pattern construction, explore [PRegEx for human-friendly regex syntax](https://codecut.ai/pregex-write-human-readable-regular-expressions-in-python-2/).\n",
        "\n",
        "# Apply preprocessing to sample data\n",
        "print(\"Before and after preprocessing:\")\n",
        "print(\"-\" * 50)\n",
        "for product in messy_products[:8]:\n",
        "    cleaned = preprocess_product_name(product)\n",
        "    print(f\"Original: {product}\")\n",
        "    print(f\"Cleaned:  {cleaned}\")\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Output:\n",
        "\n",
        "```text\n",
        "Before and after preprocessing:\n",
        "--------------------------------------------------\n",
        "Original: iPhoneÂ® 14 Pro Max\n",
        "Cleaned:  iphone 14 pro max\n",
        "\n",
        "Original: IPHONE 14 pro max\n",
        "Cleaned:  iphone 14 pro max\n",
        "\n",
        "Original: Apple iPhone 14 Pro Max 256GB\n",
        "Cleaned:  apple iphone 14 pro max 256gb\n",
        "\n",
        "Original: iPhone14ProMax\n",
        "Cleaned:  iphone14promax\n",
        "\n",
        "Original: i-Phone 14 Pro Max\n",
        "Cleaned:  i phone 14 pro max\n",
        "\n",
        "Original: Samsung Galaxy S23 Ultra\n",
        "Cleaned:  samsung galaxy s23 ultra\n",
        "\n",
        "Original: SAMSUNG Galaxy S23 Ultra 5G\n",
        "Cleaned:  samsung galaxy s23 ultra 5g\n",
        "\n",
        "Original: Galaxy S23 Ultra (512GB)\n",
        "Cleaned:  galaxy s23 ultra\n",
        "```\n",
        "\n",
        "Perfect matches emerge after cleaning formatting inconsistencies. Products 1 and 2 now match exactly, demonstrating regex's power for standardization.\n",
        "\n",
        "However, regex preprocessing fails with critical variations. Let's test exact matching after preprocessing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Test exact matching after regex preprocessing\n",
        "test_cases = [\n",
        "    (\"iPhoneÂ® 14 Pro Max\", \"IPHONE 14 pro max\", \"Case + symbols\"),\n",
        "    (\"iPhoneÂ® 14 Pro Max\", \"Apple iPhone 14 Pro Max 256GB\", \"Extra words\"),\n",
        "    (\"iPhoneÂ® 14 Pro Max\", \"iPhone14ProMax\", \"Missing spaces\"),\n",
        "    (\"Apple iPhone 14 Pro Max\", \"iPhone 14 Pro Max Apple\", \"Word order\"),\n",
        "    (\"wireless headphones\", \"bluetooth earbuds\", \"Semantic gap\")\n",
        "]\n",
        "\n",
        "# Test each case\n",
        "for product1, product2, issue_type in test_cases:\n",
        "    cleaned1 = preprocess_product_name(product1)\n",
        "    cleaned2 = preprocess_product_name(product2)\n",
        "    is_match = cleaned1 == cleaned2\n",
        "    result = \"âœ“\" if is_match else \"âœ—\"\n",
        "    print(f\"{result} {issue_type}: {is_match}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Output:\n",
        "\n",
        "```text\n",
        "âœ“ Case + symbols: True\n",
        "âœ— Extra words: False\n",
        "âœ— Missing spaces: False\n",
        "âœ— Word order: False\n",
        "âœ— Semantic gap: False\n",
        "```\n",
        "\n",
        "Regex achieves only 1/5 exact matches despite preprocessing. Success: case and symbol standardization. Failures:\n",
        "\n",
        "- **Extra words**: \"apple iphone\" vs \"iphone\" remain different\n",
        "- **Missing spaces**: \"iphone14promax\" vs \"iphone 14 pro max\" fail matching  \n",
        "- **Word reordering**: Different arrangements of identical words don't match\n",
        "- **Semantic gaps**: No shared text patterns between conceptually similar products\n",
        "\n",
        "These limitations require character-level similarity measurement instead of exact matching. Python's built-in `difflib` module provides the solution by analyzing character sequences and calculating similarity ratios.\n",
        "\n",
        "## difflib: Python's Built-in Sequence Matching\n",
        "\n",
        "difflib is a Python built-in module that provides similarity ratios. It analyzes character sequences to calculate similarity scores between text strings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from difflib import SequenceMatcher\n",
        "\n",
        "def calculate_similarity(text1, text2):\n",
        "    \"\"\"Calculate similarity ratio between two strings.\"\"\"\n",
        "    return SequenceMatcher(None, text1, text2).ratio()\n",
        "\n",
        "# Test difflib on key similarity challenges\n",
        "test_cases = [\n",
        "    (\"iphone 14 pro max\", \"iphone 14 pro max\", \"Exact match\"),\n",
        "    (\"iphone 14 pro max\", \"i phone 14 pro max\", \"Spacing variation\"), \n",
        "    (\"iphone 14 pro max\", \"apple iphone 14 pro max 256gb\", \"Extra words\"),\n",
        "    (\"iphone 14 pro max\", \"iphone14promax\", \"Missing spaces\"),\n",
        "    (\"iphone 14 pro max\", \"iphone 14 prro max\", \"Typo\"),\n",
        "    (\"apple iphone 14 pro max\", \"iphone 14 pro max apple\", \"Word order\"),\n",
        "    (\"wireless headphones\", \"bluetooth earbuds\", \"Semantic gap\")\n",
        "]\n",
        "\n",
        "for text1, text2, test_type in test_cases:\n",
        "    score = calculate_similarity(text1, text2)\n",
        "    result = \"âœ“\" if score >= 0.85 else \"âœ—\"\n",
        "    print(f\"{result} {test_type}: {score:.3f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Output:\n",
        "\n",
        "```text\n",
        "âœ“ Exact match: 1.000\n",
        "âœ“ Spacing variation: 0.971\n",
        "âœ— Extra words: 0.739\n",
        "âœ“ Missing spaces: 0.903\n",
        "âœ“ Typo: 0.971\n",
        "âœ— Word order: 0.739\n",
        "âœ— Semantic gap: 0.333\n",
        "```\n",
        "\n",
        "difflib achieves 4/7 successful matches (â‰¥0.85 threshold). Successes: exact matches, spacing variations, typos, and missing spaces. Failures:\n",
        "\n",
        "- **Word reordering**: \"Apple iPhone\" vs \"iPhone Apple\" drops to 0.739\n",
        "- **Extra content**: Additional words reduce scores to 0.739\n",
        "- **Semantic gaps**: Different words for same concept score only 0.333\n",
        "\n",
        "These results highlight difflib's core limitation: sensitivity to word order and poor handling of extra content. RapidFuzz tackles word reordering and extra content issues with sophisticated matching algorithms that understand token relationships beyond simple character comparison.\n",
        "\n",
        "## RapidFuzz: High-Performance Fuzzy String Matching\n",
        "\n",
        "[RapidFuzz](https://github.com/maxbachmann/RapidFuzz) is a high-performance fuzzy string matching library with C++ optimization. It addresses word reordering and complex text variations that difflib cannot handle effectively.\n",
        "\n",
        "To install RapidFuzz, run:\n",
        "\n",
        "```bash\n",
        "pip install rapidfuzz\n",
        "```\n",
        "\n",
        "Let's test RapidFuzz on the same test cases:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from rapidfuzz import fuzz\n",
        "\n",
        "# Test RapidFuzz using WRatio algorithm\n",
        "test_cases = [\n",
        "    (\"iphone 14 pro max\", \"iphone 14 pro max\", \"Exact match\"),\n",
        "    (\"iphone 14 pro max\", \"i phone 14 pro max\", \"Spacing variation\"),\n",
        "    (\"iphone 14 pro max\", \"apple iphone 14 pro max 256gb\", \"Extra words\"),\n",
        "    (\"iphone 14 pro max\", \"iphone14promax\", \"Missing spaces\"),\n",
        "    (\"iphone 14 pro max\", \"iphone 14 prro max\", \"Typo\"),\n",
        "    (\"apple iphone 14 pro max\", \"iphone 14 pro max apple\", \"Word order\"),\n",
        "    (\"wireless headphones\", \"bluetooth earbuds\", \"Semantic gap\"),\n",
        "    (\"macbook pro\", \"laptop computer\", \"Conceptual gap\")\n",
        "]\n",
        "\n",
        "for text1, text2, test_type in test_cases:\n",
        "    score = fuzz.WRatio(text1, text2) / 100  # Convert to 0-1 scale\n",
        "    result = \"âœ“\" if score >= 0.85 else \"âœ—\"\n",
        "    print(f\"{result} {test_type}: {score:.3f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Output:\n",
        "\n",
        "```text\n",
        "âœ“ Exact match: 1.000\n",
        "âœ“ Spacing variation: 0.971\n",
        "âœ“ Extra words: 0.900\n",
        "âœ“ Missing spaces: 0.903\n",
        "âœ“ Typo: 0.971\n",
        "âœ“ Word order: 0.950\n",
        "âœ— Semantic gap: 0.389\n",
        "âœ— Conceptual gap: 0.385\n",
        "```\n",
        "\n",
        "RapidFuzz achieves 6/8 successful matches (â‰¥0.85 threshold). Successes: exact matches, spacing, extra words, missing spaces, typos, and word order. Failures:\n",
        "\n",
        "- **Semantic gaps**: \"wireless headphones\" vs \"bluetooth earbuds\" scores only 0.389\n",
        "- **Conceptual relationships**: \"macbook pro\" vs \"laptop computer\" achieves just 0.385\n",
        "- **Pattern-only matching**: Cannot understand that different words describe same products\n",
        "\n",
        "These failures reveal RapidFuzz's fundamental limitation: it excels at text-level variations but cannot understand meaning. When products serve identical purposes using different terminology, we need semantic understanding rather than pattern matching.\n",
        "\n",
        "Sentence Transformers addresses this gap through neural language models that comprehend conceptual relationships.\n",
        "\n",
        "## Sentence Transformers: AI-Powered Semantic Similarity\n",
        "\n",
        "Surface-level text matching misses semantic relationships. [Sentence Transformers](https://github.com/UKPLab/sentence-transformers), a library built on transformer neural networks, can understand that \"wireless headphones\" and \"bluetooth earbuds\" serve identical purposes by analyzing meaning rather than just character patterns.\n",
        "\n",
        "To install Sentence Transformers, run:\n",
        "\n",
        "```bash\n",
        "pip install sentence-transformers\n",
        "```\n",
        "\n",
        "Let's test Sentence Transformers on the same test cases:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Test semantic understanding capabilities\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "test_cases = [\n",
        "    (\"iphone 14 pro max\", \"iphone 14 pro max\", \"Exact match\"),\n",
        "    (\"iphone 14 pro max\", \"i phone 14 pro max\", \"Spacing variation\"),\n",
        "    (\"iphone 14 pro max\", \"apple iphone 14 pro max 256gb\", \"Extra words\"),\n",
        "    (\"apple iphone 14 pro max\", \"iphone 14 pro max apple\", \"Word order\"),\n",
        "    (\"wireless headphones\", \"bluetooth earbuds\", \"Semantic match\"),\n",
        "    (\"macbook pro\", \"laptop computer\", \"Conceptual match\"),\n",
        "    (\"gaming console\", \"video game system\", \"Synonym match\"),\n",
        "    (\"smartphone\", \"feature phone\", \"Related concepts\")\n",
        "]\n",
        "\n",
        "for text1, text2, test_type in test_cases:\n",
        "    embeddings = model.encode([text1, text2])\n",
        "    score = cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]\n",
        "    result = \"âœ“\" if score >= 0.65 else \"âœ—\"\n",
        "    print(f\"{result} {test_type}: {score:.3f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Output:\n",
        "\n",
        "```text\n",
        "âœ“ Exact match: 1.000\n",
        "âœ“ Spacing variation: 0.867\n",
        "âœ“ Extra words: 0.818\n",
        "âœ“ Word order: 0.988\n",
        "âœ— Semantic match: 0.618\n",
        "âœ“ Conceptual match: 0.652\n",
        "âœ“ Synonym match: 0.651\n",
        "âœ— Related concepts: 0.600\n",
        "```\n",
        "\n",
        "Sentence Transformers achieves 7/8 successful matches (â‰¥0.65 threshold). Successes: all text variations plus semantic relationships. Failures:\n",
        "\n",
        "- **Edge case semantics**: \"smartphone\" vs \"feature phone\" scores only 0.600\n",
        "- **Processing overhead**: Neural inference requires significantly more computation than string algorithms\n",
        "- **Memory requirements**: Models need substantial RAM (100MB+ for basic models, GBs for advanced ones)\n",
        "- **Resource scaling**: Large datasets may require GPU acceleration for reasonable performance\n",
        "\n",
        "Sentence Transformers unlocks semantic understanding at computational cost. The decision depends on whether conceptual relationships provide sufficient business value to justify resource overhead.\n",
        "\n",
        "For implementing semantic search at production scale, see our [pgvector and Ollama integration guide](https://codecut.ai/semantic-search-postgres-pgvector-ollama/).\n",
        "\n",
        "## When to Use Each Tool\n",
        "\n",
        "### Data Preprocessing (Always Start Here)\n",
        "\n",
        "**Use regex for:**\n",
        "\n",
        "- Removing special characters and symbols\n",
        "- Standardizing case and formatting\n",
        "- Cleaning messy product names\n",
        "- Preparing text for similarity analysis\n",
        "\n",
        "### Character-Level Similarity\n",
        "\n",
        "**Use difflib when:**\n",
        "\n",
        "- Learning text similarity concepts\n",
        "- Working with small datasets (<1000 records)\n",
        "- External dependencies not allowed\n",
        "- Simple typo detection is sufficient\n",
        "\n",
        "### Production Fuzzy Matching\n",
        "\n",
        "**Use RapidFuzz when:**\n",
        "\n",
        "- Processing thousands of records\n",
        "- Need fast approximate matching\n",
        "- Handling abbreviations and variations\n",
        "- Text-level similarity is sufficient\n",
        "\n",
        "### Semantic Understanding\n",
        "\n",
        "**Use Sentence Transformers when:**\n",
        "\n",
        "- Conceptual relationships matter\n",
        "- \"wireless headphones\" should match \"bluetooth earbuds\"\n",
        "- Building recommendation systems\n",
        "- Multilingual content similarity\n",
        "- Compute resources are available\n",
        "\n",
        "### Performance vs Accuracy Tradeoff\n",
        "\n",
        "| Requirement | Recommended Tool |\n",
        "|-------------|------------------|\n",
        "| Speed > Accuracy | RapidFuzz |\n",
        "| Accuracy > Speed | Sentence Transformers |\n",
        "| No Dependencies | difflib |\n",
        "| Preprocessing Only | regex |\n",
        "\n",
        "### Decision Tree\n",
        "\n",
        "When facing a new text similarity project, use this visual guide to navigate from problem requirements to the optimal tool selection:\n",
        "\n",
        "![Decision tree flowchart showing text similarity tool selection process: starting with regex preprocessing, then branching by dataset size to small/large paths, followed by dependency and speed priority decisions leading to difflib, RapidFuzz, or Sentence Transformers solutions](https://codecut.ai/wp-content/uploads/2025/08/diagram-export-8-5-2025-8_05_52-AM.png)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}