{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Motivation\n",
        "\n",
        "> ðŸ“– Read the full article: [Version Control for Data and Models Using DVC](https://codecut.ai/introduction-to-dvc-data-version-control-tool-for-machine-learning-projects-2/)\n",
        "\n",
        "\n",
        "As a data scientist, you're constantly iterating on datasets, model configurations, and code. Reproducing past experiments becomes difficult without a system for data version control that keeps data and models in sync with code changes.\n",
        "\n",
        "Git excels at versioning source code, but it's not well-suited for tracking data and models for two major limitations:\n",
        "\n",
        "- Storing big binaries inflates the repository and slows down Git operations.\n",
        "- Changes in binary files can't be meaningfully tracked.\n",
        "\n",
        "DVC (Data Version Control) fills this gap by extending Git to handle data and models efficiently. This article shows how to use DVC to:\n",
        "\n",
        "- Track and store datasets alongside Git-managed code\n",
        "- Build reproducible pipelines and log models with MLflow\n",
        "\n",
        "## What Is DVC?\n",
        "\n",
        "[DVC](https://dvc.org/doc/start) is an open-source tool that brings data and model versioning into Git workflows. Instead of storing bulky files directly in Git, DVC saves them in external storage and tracks their metadata with lightweight `.dvc` files.\n",
        "\n",
        "> ðŸ“š For comprehensive data versioning strategies in production environments, check out [Production-Ready Data Science](https://codecut.ai/production-ready-data-science/).\n",
        "\n",
        "![](https://codecut.ai/wp-content/uploads/2023/02/Git-1.png)\n",
        "\n",
        "If you're comfortable with Git, DVC will feel familiar.\n",
        "\n",
        "Install it using either of the following options:\n",
        "\n",
        "- Using pip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pip install dvc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Using uv (a faster Python package manager)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "uv add dvc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Getting Started\n",
        "\n",
        "Initialize DVC inside an existing Git repository:\n",
        "\n",
        "```bash\n",
        "dvc init\n",
        "```\n",
        "\n",
        "After running `dvc init`, DVC sets up the project with the necessary configuration to start tracking data. Your directory structure will look like this:\n",
        "\n",
        "```\n",
        ".\n",
        "â”œâ”€â”€ .dvc/                 # DVC config and internal files\n",
        "â”œâ”€â”€ .dvcignore            # Like .gitignore but for DVC operations\n",
        "â”œâ”€â”€ .git/                 # Git repository\n",
        "â””â”€â”€ (your project files)\n",
        "```\n",
        "\n",
        "## Tracking Data\n",
        "\n",
        "![](https://codecut.ai/wp-content/uploads/2023/02/track_file.png)\n",
        "\n",
        "Assume you have a `data/` directory with your raw files.\n",
        "\n",
        "To start tracking it:\n",
        "\n",
        "```bash\n",
        "dvc add data/\n",
        "```\n",
        "\n",
        "This creates a `data.dvc` file with metadata like:\n",
        "\n",
        "```yaml\n",
        "outs:\n",
        "- md5: 86451bd526f5f95760f0b7a412508746.dir\n",
        "  path: data\n",
        "```\n",
        "\n",
        "Then commit the metadata to Git:\n",
        "\n",
        "```bash\n",
        "git add data.dvc .gitignore\n",
        "git commit -m \"Track dataset with DVC\"\n",
        "```\n",
        "\n",
        "When you run `dvc add data/`, DVC also creates or updates a `.gitignore` file to prevent Git from tracking the actual `data/` directory.\n",
        "\n",
        "The directory structure after running `dvc add data/` looks like this:\n",
        "\n",
        "```bash\n",
        ".\n",
        "â”œâ”€â”€ data/                  # Contains your actual dataset (ignored by Git)\n",
        "â”œâ”€â”€ data.dvc               # Metadata file tracked by Git\n",
        "â””â”€â”€ .gitignore             # Contains an entry to ignore /data/\n",
        "```\n",
        "\n",
        "The `.gitignore` file will include an entry like:\n",
        "\n",
        "```\n",
        "data/\n",
        "```\n",
        "\n",
        "This ensures that only the lightweight `.dvc` metadata file is versioned, while the large data files are managed separately through DVC's external storage system.\n",
        "\n",
        "## Storing Data Remotely\n",
        "\n",
        "![](https://codecut.ai/wp-content/uploads/2023/02/Store-data-remotely.png)\n",
        "\n",
        "DVC supports many storage backends like S3, GCS, Azure, SSH, and Google Drive.\n",
        "\n",
        "To use Amazon S3:\n",
        "\n",
        "1. Make sure your AWS credentials are configured (e.g. with `aws configure`)\n",
        "2. Create or choose an existing S3 bucket (e.g. `my-dvc-bucket`)\n",
        "\n",
        "Then configure the remote:\n",
        "\n",
        "```bash\n",
        "dvc remote add -d myremote s3://my-dvc-bucket/path/to/data\n",
        "```\n",
        "\n",
        "This saves a remote entry in `.dvc/config`:\n",
        "\n",
        "```toml\n",
        "[core]\n",
        "    remote = myremote\n",
        "\n",
        "['remote \"myremote\"']\n",
        "    url = s3://my-dvc-bucket/path/to/data\n",
        "```\n",
        "\n",
        "Commit the config:\n",
        "\n",
        "```bash\n",
        "git add .dvc/config\n",
        "git commit -m \"Configure S3 remote for DVC\"\n",
        "```\n",
        "\n",
        "Then push your data:\n",
        "\n",
        "```bash\n",
        "dvc push\n",
        "```\n",
        "\n",
        "The actual data goes to Amazon S3. The only files stays in your Git repo are:\n",
        "\n",
        "- `.dvc/`: a directory that stores DVC configuration, cache, and metadata files.\n",
        "- `data.dvc`: the metadata file tracking your raw data directory\n",
        "\n",
        "## Retrieving Data\n",
        "\n",
        "![](https://codecut.ai/wp-content/uploads/2023/02/get-the-data.png)\n",
        "\n",
        "Suppose you just joined a project that uses DVC to manage datasets and model files. After cloning the Git repository, you might only see `.dvc` files and pipeline definitions, but not the actual data content.\n",
        "\n",
        "For example:\n",
        "\n",
        "```bash\n",
        ".\n",
        "â””â”€â”€ data/\n",
        "    â””â”€â”€ raw.dvc\n",
        "```\n",
        "\n",
        "The `.dvc` file contains metadata pointing to the data stored in a remote location. To download and restore the full dataset locally, simply run:\n",
        "\n",
        "```bash\n",
        "dvc pull\n",
        "```\n",
        "\n",
        "This command downloads the required files from the configured remote storage and rebuilds the full directory structure:\n",
        "\n",
        "```bash\n",
        ".\n",
        "â””â”€â”€ data/\n",
        "    â”œâ”€â”€ final/\n",
        "    â”‚   â””â”€â”€ segmented.csv\n",
        "    â”œâ”€â”€ intermediate/\n",
        "    â”‚   â””â”€â”€ scale_features.csv\n",
        "    â”œâ”€â”€ raw/\n",
        "    â”‚   â””â”€â”€ marketing_campaign.csv\n",
        "    â””â”€â”€ raw.dvc\n",
        "```\n",
        "\n",
        "## Switching Between Versions\n",
        "\n",
        "![](https://codecut.ai/wp-content/uploads/2023/02/switch-between-versions.png)\n",
        "\n",
        "Without a reliable workflow, it's easy to accidentally pair the wrong version of code with the wrong version of data, leading to results you can't reproduce or trust."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Example of mismatch: Code expects 'feature' to be in range [1, 2, 3], but data has changed\n",
        "\n",
        "model_input = pd.read_csv(\"data.csv\")\n",
        "assert model_input['feature'].max() <= 3, \"Feature values exceed expected range\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "DVC's `dvc checkout` command makes it easy to switch between data and model versions tied to specific Git commits or branches.\n",
        "\n",
        "To demonstrate, let's track and switch between two dataset versions.\n",
        "\n",
        "First, create the initial version of the dataset using a Python script:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# example.py\n",
        "import pandas as pd\n",
        "\n",
        "# Create version 1 of dataset\n",
        "df_v1 = pd.DataFrame({\"feature\": [1, 2, 3], \"target\": [0, 1, 0]})\n",
        "df_v1.to_csv(\"data.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From the terminal, run the script and track the dataset with DVC:\n",
        "\n",
        "```python\n",
        "python example.py\n",
        "dvc add data.csv\n",
        "git add data.csv.dvc .gitignore\n",
        "git commit -m \"Version 1 of data\"\n",
        "```\n",
        "\n",
        "Next, simulate an updated dataset version:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# example.py\n",
        "import pandas as pd\n",
        "\n",
        "# Overwrite data.csv with version 2\n",
        "df_v2 = pd.DataFrame({\"feature\": [10, 20, 30], \"target\": [1, 0, 1]})\n",
        "df_v2.to_csv(\"data.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Track the updated dataset:\n",
        "\n",
        "```python\n",
        "dvc add data.csv\n",
        "git add data.csv.dvc\n",
        "git commit -m \"Version 2 of data\"\n",
        "```\n",
        "\n",
        "Now switch back to version 1:\n",
        "\n",
        "```python\n",
        "git checkout HEAD~1\n",
        "dvc checkout\n",
        "```\n",
        "\n",
        "This restores `data.csv` to its original state:\n",
        "\n",
        "| Feature | Target |\n",
        "|---------|--------|\n",
        "| 1       | 0      |\n",
        "| 2       | 1      |\n",
        "| 3       | 0      |\n",
        "\n",
        "As shown, the dataset now reflects version 1 again, keeping your data aligned with the code at that point in history.\n",
        "\n",
        "## Building a DVC Pipeline\n",
        "\n",
        "![](https://codecut.ai/wp-content/uploads/2023/02/data-pipeline.png)\n",
        "\n",
        "Beyond tracking data, DVC allows you to create **reproducible machine learning pipelines** that connect stages like preprocessing and training.\n",
        "\n",
        "Here's an example of a pipeline defined in `dvc.yaml` with two stages: `process_data` and `train`.\n",
        "\n",
        "```yaml\n",
        "stages:\n",
        "  process_data:\n",
        "    cmd: python src/process_data.py\n",
        "    deps:\n",
        "    - data/raw\n",
        "    - src/process_data.py\n",
        "    - config\n",
        "    outs:\n",
        "    - data/intermediate\n",
        "  train:\n",
        "    cmd: python src/segment.py\n",
        "    deps:\n",
        "    - data/intermediate\n",
        "    - src/segment.py\n",
        "    - config\n",
        "    outs:\n",
        "    - data/final\n",
        "    - model/cluster.pkl\n",
        "```\n",
        "\n",
        "`dvc.yaml` defines each pipeline stage and how DVC should execute and track it. The file includes:\n",
        "\n",
        "- `stages`: A top-level section that holds each named stage of the pipeline\n",
        "- Each stage name (e.g. `process_data`, `train`) maps to one pipeline step\n",
        "- `cmd`: The command DVC should run for that stage\n",
        "- `deps`: Dependencies the stage needs, such as data files, Python scripts, or configuration files\n",
        "- `outs`: Outputs the stage generates, which DVC will version and manage automatically\n",
        "\n",
        "Run the entire pipeline with:\n",
        "\n",
        "```bash\n",
        "dvc repro\n",
        "```\n",
        "\n",
        "DVC will only re-run stages whose inputs or dependencies have changed.\n",
        "\n",
        "For example, changing the code in `src/segment.py` will trigger only the affected stage:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def get_pca_model(data: pd.DataFrame) -> PCA:\n",
        "    pca = PCA(n_components=4)  # changed from 3 to 4\n",
        "    pca.fit(data)\n",
        "    return pca"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then run:\n",
        "\n",
        "```bash\n",
        "dvc repro\n",
        "```\n",
        "\n",
        "DVC output:\n",
        "\n",
        "```python\n",
        "'data/raw.dvc' didn't change, skipping\n",
        "Stage 'process_data' didn't change, skipping\n",
        "Running stage 'train':\n",
        "> python src/segment.py\n",
        "```\n",
        "\n",
        "Only the `train` stage is re-executed. This targeted re-execution improves pipeline efficiency and preserves consistency.\n",
        "\n",
        "You can visualize the pipeline with:\n",
        "\n",
        "```bash\n",
        "dvc dag\n",
        "```\n",
        "\n",
        "This shows a graph of your pipeline stages and their relationships.\n",
        "\n",
        "```bash\n",
        "+--------------+\n",
        "| data/raw.dvc |\n",
        "+--------------+\n",
        "        *\n",
        "        *\n",
        "        *\n",
        "+--------------+\n",
        "| process_data |\n",
        "+--------------+\n",
        "        *\n",
        "        *\n",
        "        *\n",
        "    +-------+\n",
        "    | train |\n",
        "    +-------+\n",
        "```\n",
        "\n",
        "## DVC vs MLflow: Roles and Integration\n",
        "\n",
        "DVC and [MLflow](https://mlflow.org/) both support reproducibility in machine learning projects, but they target different aspects of the workflow:\n",
        "\n",
        "- **DVC** focuses on version-controlling datasets, models, and pipelines. It ensures consistency and scalability by integrating tightly with Git and external storage.\n",
        "- **MLflow** is built for experiment managementâ€”logging parameters, metrics, and artifacts to compare different runs.\n",
        "\n",
        "![](https://codecut.ai/wp-content/uploads/2023/02/dvc-vs-mlflow.png)\n",
        "\n",
        "### Key Differences\n",
        "\n",
        "| Feature | DVC | MLflow |\n",
        "|---------|-----|---------|\n",
        "| Primary Focus | Data and model file versioning | Experiment tracking and model registry |\n",
        "| Storage | External file systems (S3, etc) | Local filesystem, S3, Azure, GCS |\n",
        "| Git Integration | Yes | Optional |\n",
        "| Pipeline Support | Yes (`dvc.yaml`) | No |\n",
        "| Metrics Tracking | Basic (`.json`, `.tsv`) | Extensive (via `mlflow.log_*`) |\n",
        "| Web UI | No (3rd-party only) | Yes (`mlflow ui`) |\n",
        "\n",
        "### How to Integrate DVC and MLflow\n",
        "\n",
        "You can combine DVC and MLflow for a powerful, end-to-end MLOps workflow:\n",
        "\n",
        "- Use DVC to manage and version datasets, models, and pipeline outputs\n",
        "- Use MLflow to log parameters, metrics, and artifacts for experiment tracking and comparison\n",
        "\n",
        "This code shows how to integrate DVC and MLflow in a pipeline stage defined in `segment.py`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Save artifacts to disk so DVC can version and track them\n",
        "save_data_and_model(data, model, config)\n",
        "\n",
        "# Log run metadata, metrics, and models with MLflow\n",
        "with mlflow.start_run():\n",
        "\n",
        "    mlflow.log_params({\"n_components\": 3, \"random_state\": 42, \"best_k\": k_best})\n",
        "    mlflow.log_metric(\"silhouette_score\", silhouette_avg)\n",
        "    signature = infer_signature(pca_df, pred)\n",
        "    mlflow.sklearn.log_model(\n",
        "        model, \"kmeans_model\", signature=signature, input_example=pca_df.head()\n",
        "    )\n",
        "    mlflow.log_artifact(config.final.path, \"processed_data\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reproduce the pipeline stages and sync the outputs to remote storage with DVC:\n",
        "\n",
        "```bash\n",
        "dvc repro\n",
        "dvc push\n",
        "```\n",
        "\n",
        "This integration ensures data and code are reproducible via DVC, while experiment metadata is logged in MLflow.\n",
        "\n",
        "## Automating DVC with Git Hooks\n",
        "\n",
        "Without automation, it's easy to forget critical DVC stepsâ€”like running `dvc push` after updating data, or `dvc checkout` after switching Git branches.\n",
        "\n",
        "DVC integrates with [pre-commit](https://codecut.ai/how-to-structure-a-data-science-project-for-readability-and-transparency-2/#h-check-issues-in-your-code-before-committing) to streamline automation of DVC operations like syncing, pushing, and restoring data.\n",
        "\n",
        "![](https://codecut.ai/wp-content/uploads/2025/05/pre-commit.png)\n",
        "\n",
        "You can configure DVC's pre-commit integration automatically with:\n",
        "\n",
        "```bash\n",
        "dvc install --use-pre-commit-tool\n",
        "```\n",
        "\n",
        "Or manually add the following to your `.pre-commit-config.yaml`:\n",
        "\n",
        "```yaml\n",
        "repos:\n",
        "- repo: https://github.com/iterative/dvc\n",
        "  rev: 3.59.2\n",
        "  hooks:\n",
        "  - id: dvc-pre-commit\n",
        "    additional_dependencies:\n",
        "    - .[all]\n",
        "    language_version: python3\n",
        "    stages:\n",
        "    - pre-commit\n",
        "  - id: dvc-pre-push\n",
        "    additional_dependencies:\n",
        "    - .[all]\n",
        "    language_version: python3\n",
        "    stages:\n",
        "    - pre-push\n",
        "  - id: dvc-post-checkout\n",
        "    additional_dependencies:\n",
        "    - .[all]\n",
        "    language_version: python3\n",
        "    stages:\n",
        "    - post-checkout\n",
        "    always_run: true\n",
        "```\n",
        "\n",
        "The `pre-commit` framework only installs the `pre-commit` hook by default. To enable the `pre-push` and `post-checkout` hooks, run:\n",
        "\n",
        "```bash\n",
        "pre-commit install --hook-type pre-push --hook-type post-checkout --hook-type pre-commit\n",
        "```\n",
        "\n",
        "### Try It Out\n",
        "\n",
        "Once you've set up Git hooks (manually or using pre-commit), you can verify they work with this simple test:\n",
        "\n",
        "1. Modify a tracked file (e.g. update a notebook or a script).\n",
        "2. Stage and commit the change:\n",
        "\n",
        "```bash\n",
        "git add src/train.py\n",
        "git commit -m \"Update training logic\"\n",
        "```\n",
        "\n",
        "If the pre-commit hook is installed correctly, you'll see output showing the result of running `dvc status`, such as:\n",
        "\n",
        "```bash\n",
        "DVC pre-commit....................................Passed\n",
        "- hook id: dvc-pre-commit\n",
        "- duration: 0.4s\n",
        "\n",
        "process_data:\n",
        "        changed deps:\n",
        "                modified:           config\n",
        "train:\n",
        "        changed deps:\n",
        "                modified:           config\n",
        "```\n",
        "\n",
        "3. Push the commit:\n",
        "\n",
        "```bash\n",
        "git push\n",
        "```\n",
        "\n",
        "If the pre-push hook is active, you'll see the output from `dvc push`, such as:\n",
        "\n",
        "```bash\n",
        "DVC pre-push....................................Passed\n",
        "```\n",
        "\n",
        "This confirms that the pre-push hook is uploading data and models using `dvc push`."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}