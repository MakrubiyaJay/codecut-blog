{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Why Should Data Scientists Switch from Print to Logging {#why-should-data-scientists-switch-from-print-to-logging}\n",
        "\n",
        "> ðŸ“– Read the full article: [Loguru: Simple as Print, Powerful as Logging](https://codecut.ai/simplify-your-python-logging-with-loguru/)\n",
        "\n",
        "\n",
        "As your data science projects evolve from notebooks to production-ready pipelines, `print()` becomes harder to manage.\n",
        "\n",
        "For example, consider the following data science project where you want to track different stages like data loading, preprocessing, model training, and error handling:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Loaded 1000 rows from dataset.csv\")\n",
        "print(\"Started training RandomForest model\")\n",
        "print(\"Missing values detected in 'age' column\")\n",
        "print(\"Model training failed: insufficient memory\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Output:\n",
        "\n",
        "```python\n",
        "Loaded 1000 rows from dataset.csv\n",
        "Started training RandomForest model\n",
        "Missing values detected in 'age' column\n",
        "Model training failed: insufficient memory\n",
        "```\n",
        "\n",
        "This works fine locally, but in a production environment:\n",
        "\n",
        "- There's no record of when these events occurred\n",
        "- There's no way to save that record to a file for later inspection\n",
        "- There's no indication of the severity of each message, making it hard to distinguish between general informational messages and serious runtime errors\n",
        "\n",
        "Unlike `print`, the `logging` module supports **log levels**, **output formatting**, and **destination control** (file, stdout, etc.). Here's a quick comparison:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# logging_example.py\n",
        "import logging\n",
        "\n",
        "logging.basicConfig(\n",
        "    level=logging.DEBUG,\n",
        "    format=\"%(asctime)s | %(levelname)s | %(module)s:%(funcName)s:%(lineno)d - %(message)s\",\n",
        "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
        ")\n",
        "\n",
        "def main():\n",
        "    logging.debug(\"Loaded 1000 rows from dataset.csv\")\n",
        "    logging.info(\"Started training RandomForest model\")\n",
        "    logging.warning(\"Missing values detected in 'age' column\")\n",
        "    logging.error(\"Model training failed: insufficient memory\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Output:\n",
        "\n",
        "```python\n",
        "2025-05-03 14:14:32 | DEBUG | logging_example:main:11 - Loaded 1000 rows from dataset.csv\n",
        "2025-05-03 14:14:32 | INFO | logging_example:main:12 - Started training RandomForest model\n",
        "2025-05-03 14:14:32 | WARNING | logging_example:main:13 - Missing values detected in 'age' column\n",
        "2025-05-03 14:14:32 | ERROR | logging_example:main:14 - Model training failed: insufficient memory\n",
        "```\n",
        "\n",
        "You can hide debug logs and focus only on more critical messages by changing the log level to INFO:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s | %(levelname)s | %(module)s:%(funcName)s:%(lineno)d - %(message)s\",\n",
        "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Output:\n",
        "\n",
        "```python\n",
        "2025-05-03 14:35:29 | INFO | logging_example:main:12 - Started training RandomForest model\n",
        "2025-05-03 14:35:29 | WARNING | logging_example:main:13 - Missing values detected in 'age' column\n",
        "2025-05-03 14:35:29 | ERROR | logging_example:main:14 - Model training failed: insufficient memory\n",
        "```\n",
        "\n",
        "## Why Many Data Scientists Still Use Print {#why-many-data-scientists-still-use-print}\n",
        "\n",
        "`print()` is fast, familiar, and doesn't require setup. When exploring data or debugging inside a Jupyter notebook, it feels like the most convenient option."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Training complete\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Thus, many data scientists prefer using print statements, even though the built-in logging module offers greater structure, flexibility, and long-term maintainability.\n",
        "\n",
        "## Meet Loguru: The Best of Both Worlds {#meet-loguru-the-best-of-both-worlds}\n",
        "\n",
        "**[Loguru](https://github.com/Delgan/loguru)** makes logging **effortless** without sacrificing power. There is no boilerplate, no custom handlers. Just drop it in and go.\n",
        "\n",
        "\n",
        "> ðŸ“š For comprehensive production logging strategies including loguru, check out [Production-Ready Data Science](https://codecut.ai/production-ready-data-science/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from loguru import logger\n",
        "\n",
        "def main():\n",
        "    logger.debug(\"Loaded 1000 rows from dataset.csv\")\n",
        "    logger.info(\"Started training RandomForest model\")\n",
        "    logger.warning(\"Missing values detected in 'age' column, using median imputation\")\n",
        "    logger.error(\"Model training failed: insufficient memory\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Default output is colored, timestamped, and detailed.**\n",
        "\n",
        "![Screenshot showing colorized Loguru output with timestamps, log levels, and message content](https://codecut.ai/wp-content/uploads/2023/07/loguru.png)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Format Logs Easily {#format-logs-easily}\n",
        "\n",
        "Formatting logs allows you to add useful information to logs such as timestamps, log levels, module names, function names, and line numbers. Here's how to do it with both logging and Loguru:\n",
        "\n",
        "### Traditional Way {#traditional-way}\n",
        "\n",
        "The traditional logging approach uses the % formatting, which is not intuitive to use and maintain:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s | %(levelname)s | %(module)s:%(funcName)s:%(lineno)d - %(message)s\",\n",
        "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loguru Way {#loguru-way}\n",
        "\n",
        "In contrast, Loguru uses the {} formatting, which is much more readable and easy to use:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import sys\n",
        "from loguru import logger\n",
        "\n",
        "# Remove the default handler\n",
        "logger.remove()\n",
        "\n",
        "# Add a stream handler\n",
        "logger.add(\n",
        "    sys.stdout,\n",
        "    format=\"{time:YYYY-MM-DD HH:mm:ss} | {level} | {module}:{function}:{line} - {message}\",\n",
        "    level=\"INFO\",\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the code above:\n",
        "\n",
        "- `logger.remove()` clears the default Loguru handler so that only your custom configuration is active.\n",
        "- `logger.add(sys.stdout, ...)` explicitly adds a stream handler that logs to the terminal using your specified format and log level.\n",
        "\n",
        "Other common options for time formatting:\n",
        "\n",
        "| Category | Token | Output Example |\n",
        "|----------|-------|----------------|\n",
        "| Year | YYYY | 2025 |\n",
        "| Month | MM | 01 â€¦ 12 |\n",
        "| Day | DD | 01 â€¦ 31 |\n",
        "| Day of Week | ddd | Mon, Tue, Wed |\n",
        "| Hour (24h) | HH | 00 â€¦ 23 |\n",
        "| Hour (12h) | hh | 01 â€¦ 12 |\n",
        "| Minute | mm | 00 â€¦ 59 |\n",
        "| Second | ss | 00 â€¦ 59 |\n",
        "| Microsecond | SSSSSS | 000000 â€¦ 999999 |\n",
        "| AM/PM | A | AM, PM |\n",
        "| Timezone | Z | +00:00, -07:00 |\n",
        "\n",
        "## Save Logs to File {#save-logs-to-file}\n",
        "\n",
        "Saving logs to a file can help preserve important information over time and aid debugging. Here's how to do it with both `logging` and Loguru:\n",
        "\n",
        "### Traditional Way {#traditional-way-1}\n",
        "\n",
        "Saving logs to both a file and the terminal using the `logging` module requires setting up separate handlers:\n",
        "\n",
        "- `FileHandler`: writes log messages to a specified file so that they can be reviewed later\n",
        "- `StreamHandler`: sends log messages to the console (stdout), allowing you to see logs in real time during execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig(\n",
        "    level=logging.DEBUG,\n",
        "    format=\"%(asctime)s | %(levelname)s | %(module)s:%(funcName)s:%(lineno)d - %(message)s\",\n",
        "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
        "    handlers=[\n",
        "        logging.FileHandler(filename=\"info.log\"),\n",
        "        logging.StreamHandler(),\n",
        "    ],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loguru Way {#loguru-way-1}\n",
        "\n",
        "Logging to a file using Loguru is simple: call the `add()` method with the file path, format, and log level. Loguru logs to the terminal by default, so calling `add()` for a file automatically saves logs to both the file and the terminal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from loguru import logger\n",
        "\n",
        "logger.add(\n",
        "    \"info.log\",\n",
        "    format=\"{time:YYYY-MM-DD HH:mm:ss} | {level} | {module}:{function}:{line} - {message}\",\n",
        "    level=\"INFO\",\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Rotate and Retain Logs {#rotate-and-retain-logs}\n",
        "\n",
        "Without log rotation, long-running processes like ETL jobs or model training can generate massive log files that waste disk space and are hard to manage. Automatic rotation keeps logs compact and readable.\n",
        "\n",
        "Here's how to do it with both logging and Loguru:\n",
        "\n",
        "### Traditional Way {#traditional-way-2}\n",
        "\n",
        "To automatically rotate the log file using the logging module, you need to use `TimedRotatingFileHandler`, which has the following key parameters:\n",
        "\n",
        "- `filename`: the file where logs are written.\n",
        "- `when`: the time interval to trigger a new log file (e.g., `'S'` for seconds, `'M'` for minutes, `'H'` for hours, `'D'` for days, `'W0'`â€“ `'W6'` for weekdays, `'midnight'` for daily at midnight).\n",
        "- `interval`: how often rotation should happen based on the unit provided in `when`.\n",
        "- `backupCount`: how many rotated log files to keep before old ones are deleted.\n",
        "\n",
        "This setup gives you finer control, but requires more manual configuration than Loguru."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import logging\n",
        "from logging.handlers import TimedRotatingFileHandler\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "logger.setLevel(logging.DEBUG)\n",
        "\n",
        "handler = TimedRotatingFileHandler(\"debug.log\", when=\"W0\", interval=1, backupCount=4)\n",
        "handler.setLevel(logging.INFO)\n",
        "handler.setFormatter(\n",
        "    logging.Formatter(\n",
        "        \"%(asctime)s | %(levelname)s | %(module)s:%(funcName)s:%(lineno)d - %(message)s\",\n",
        "        datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
        "    )\n",
        ")\n",
        "logger.addHandler(handler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loguru Way {#loguru-way-2}\n",
        "\n",
        "With Loguru, you can rotate and retain logs in a single line using the `rotation` and `retention` parameters in `add()`:\n",
        "\n",
        "- `rotation`: when to create a new log file (e.g., size or time)\n",
        "- `retention`: how long to keep old log files\n",
        "\n",
        "No extra classes or handlers required:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from loguru import logger\n",
        "\n",
        "logger.add(\"debug.log\", level=\"INFO\", rotation=\"1 week\", retention=\"4 weeks\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can also customize log rotation and retention rules in Loguru using different triggers and strategies:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "logger.add(\"file_1.log\", rotation=\"500 MB\")    # Automatically rotate if the file exceeds 500 MB\n",
        "logger.add(\"file_2.log\", rotation=\"12:00\")      # Create a new log file daily at noon\n",
        "logger.add(\"file_3.log\", rotation=\"1 week\")     # Rotate weekly\n",
        "\n",
        "logger.add(\"file_X.log\", retention=\"10 days\")   # Keep logs for 10 days, then delete old ones\n",
        "\n",
        "logger.add(\"file_Y.log\", compression=\"zip\")     # Compress rotated logs to save space"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Better Exception Logging {#better-exception-logging}\n",
        "\n",
        "When exceptions occur, logging can help you understand not only what went wrong, but also where and why. Here's how traditional logging compares with Loguru when it comes to capturing exception details:\n",
        "\n",
        "### Traditional Way {#traditional-way-3}\n",
        "\n",
        "To catch and log exceptions using the built-in `logging` module, you typically wrap your code in a try-except block and call `logging.exception()` to capture the traceback:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import logging\n",
        "\n",
        "def divide(a, b):\n",
        "    return a / b\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        divide(1, 0)\n",
        "    except ZeroDivisionError:\n",
        "        logging.exception(\"Division by zero\")\n",
        "\n",
        "main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Output:\n",
        "\n",
        "```python\n",
        "2025-05-03 15:23:09 | ERROR | logging_example:nested:18 - ZeroDivisionError\n",
        "Traceback (most recent call last):\n",
        "  File \".../logging_example.py\", line 16, in nested\n",
        "    division(1, c)\n",
        "  File \".../logging_example.py\", line 11, in division\n",
        "    return a / b\n",
        "           ~~^~~\n",
        "ZeroDivisionError: division by zero\n",
        "```\n",
        "\n",
        "The stack trace is printed, but you don't see the values of `a` and `b`, so you're left guessing what inputs caused the failure.\n",
        "\n",
        "### Loguru Way {#loguru-way-3}\n",
        "\n",
        "Loguru improves debugging by capturing the full stack trace and the state of local variables at each level."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from loguru import logger\n",
        "\n",
        "def division(a, b):\n",
        "    return a / b\n",
        "\n",
        "def nested(c):\n",
        "    try:\n",
        "        division(1, c)\n",
        "    except ZeroDivisionError:\n",
        "        logger.exception(\"ZeroDivisionError\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    nested(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Output:\n",
        "\n",
        "```python\n",
        "> File \".../catch_decorator.py\", line 14, in <module>\n",
        "    nested(0)\n",
        "    â”” <function nested at 0x106492520>\n",
        "\n",
        "  File \".../catch_decorator.py\", line 10, in nested\n",
        "    division(1, c)\n",
        "    â”‚           â”” 0\n",
        "    â”” <function division at 0x105051800>\n",
        "\n",
        "  File \".../catch_decorator.py\", line 5, in division\n",
        "    return a / b\n",
        "           â”‚   â”” 0\n",
        "           â”” 1\n",
        "\n",
        "ZeroDivisionError: division by zero\n",
        "```\n",
        "\n",
        "In the traceback above, Loguru shows that `a` is 1 and `b` is 0, making it immediately clear what inputs caused the failure.\n",
        "\n",
        "You can also capture and display full tracebacks in any function simply by adding the `@logger.catch` decorator:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from loguru import logger\n",
        "\n",
        "def divide(a, b):\n",
        "    return a / b\n",
        "\n",
        "@logger.catch\n",
        "def main():\n",
        "    divide(1, 0)\n",
        "\n",
        "main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Should I Always Use Loguru Instead of Print? {#should-i-always-use-loguru-instead-of-print}\n",
        "\n",
        "`print()` is perfectly fine for quick checks or exploratory work inside a Jupyter notebook. It's simple, fast, and requires no setup.\n",
        "\n",
        "However, when your code starts to include multiple stages, like data loading, preprocessing, modeling, and evaluation, or needs to run reliably in production, it's worth moving to a logging tool like Loguru."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}