{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prerequisites {#prerequisites}\n",
        "\n",
        "Make sure you have the following packages installed:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pip install pydantic openai pydantic-ai"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You also need access to the OpenAI API with a valid key:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "export OPENAI_API_KEY=\"your-api-key\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Core Workflow: Building a Type-Safe Agent {#core-workflow-building-a-type-safe-agent}\n",
        "\n",
        "First, define a `Pydantic` Model that describes the expected structure of your agent's output:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pydantic import BaseModel\n",
        "from typing import List\n",
        "\n",
        "class ApplicantProfile(BaseModel):\n",
        "    first_name: str\n",
        "    last_name: str\n",
        "    experience_years: int\n",
        "    primary_skill: List[str]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This model acts as a contract, ensuring that the language model returns a structured object with the correct fields and types.\n",
        "\n",
        "Now, use the `output_type` parameter to connect this model to your agent:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pydantic_ai import Agent\n",
        "\n",
        "agent = Agent(\n",
        "    'gpt-4o-mini-2024-07-18',\n",
        "    system_prompt='Extract name, years of experience, and primary skill from the job applicant description.',\n",
        "    output_type=ApplicantProfile,\n",
        ")\n",
        "\n",
        "result = agent.run_sync('Khuyen Tran is a data scientist with 5 years of experience, skilled in Python and machine learning.')\n",
        "print(result.output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Output:\n",
        "\n",
        "```python\n",
        "first_name='Khuyen' last_name='Tran' experience_years=5 primary_skill=['Python', 'machine learning']\n",
        "```\n",
        "\n",
        "This structured output is safe to pass directly into downstream applications without modification.\n",
        "\n",
        "`result.output` returns a Pydantic object. To convert it into a standard Python dictionary for further use, call:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "result.output.model_dump()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Output:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"first_name\": \"Khuyen\",\n",
        "  \"last_name\": \"Tran\",\n",
        "  \"experience_years\": 5,\n",
        "  \"primary_skill\": [\n",
        "    \"Python\",\n",
        "    \"machine learning\"\n",
        "  ]\n",
        "}\n",
        "```\n",
        "\n",
        "You can now easily integrate this into other data workflows. For example, to convert the output into a pandas DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame([result.output.model_dump()])\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Output:\n",
        "\n",
        "```python\n",
        "  first_name last_name  experience_years     primary_skill\n",
        "0     Khuyen      Tran                 5            Python\n",
        "1     Khuyen      Tran                 5  machine learning\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "## Using the DuckDuckGo Search Tool {#using-the-duckduckgo-search-tool}\n",
        "\n",
        "Have you ever tried to make your AI app respond to current events or user queries with real-world data without managing a custom search backend?\n",
        "\n",
        "PydanticAI supports integrating tools like [DuckDuckGo search](https://ai.pydantic.dev/common-tools/#duckduckgo-search-tool) to enhance your AI agents with live web results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pydantic import BaseModel\n",
        "from pydantic_ai import Agent\n",
        "from pydantic_ai.common_tools.duckduckgo import duckduckgo_search_tool\n",
        "from typing import List\n",
        "\n",
        "class UnemploymentDataSource(BaseModel):\n",
        "    title: List[str]\n",
        "    description: List[str]\n",
        "    url: List[str]\n",
        "\n",
        "# Define the agent with DuckDuckGo search tool\n",
        "search_agent = Agent(\n",
        "    'gpt-4o-mini-2024-07-18',\n",
        "    tools=[duckduckgo_search_tool()],\n",
        "    system_prompt='Search DuckDuckGo and return links or resources that match the query.',\n",
        "    output_type=UnemploymentDataSource,\n",
        ")\n",
        "\n",
        "# Run a search for unemployment rate dataset\n",
        "unemployment_result = search_agent.run_sync(\n",
        "    'Monthly unemployment rate dataset for US from 2018 to 2024'\n",
        ")\n",
        "\n",
        "print(unemployment_result.output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Example output:\n",
        "\n",
        "```python\n",
        "title=[\n",
        "  'Civilian unemployment rate - U.S. Bureau of Labor Statistics',\n",
        "  'Databases, Tables & Calculators by Subject - U.S. Bureau of Labor Statistics',\n",
        "  'Unemployment Rate (UNRATE) | FRED | St. Louis Fed',\n",
        "  'US Unemployment Rate Monthly Analysis: Employment Situation - YCharts',\n",
        "  'U.S. Unemployment Rate 1991-2025 - Macrotrends'\n",
        "]\n",
        "description=[\n",
        "  'The U.S. Bureau of Labor Statistics provides information on the civilian unemployment rate.',\n",
        "  'Access various data tables and calculators related to employment situations in the U.S.',\n",
        "  \"Access historical unemployment rates and data through the St. Louis Fed's FRED database.\",\n",
        "  'In-depth view into historical data of the U.S. unemployment rate including projections.',\n",
        "  'Details on U.S. unemployment rate trends and statistics from 1991 to 2025.'\n",
        "]\n",
        "url=[\n",
        "  'https://www.bls.gov/charts/employment-situation/civilian-unemployment-rate.htm',\n",
        "  'https://www.bls.gov/data/',\n",
        "  'https://fred.stlouisfed.org/series/UNRATE/',\n",
        "  'https://ycharts.com/indicators/us_unemployment_rate',\n",
        "  'https://www.macrotrends.net/global-metrics/countries/USA/united-states/unemployment-rate'\n",
        "]\n",
        "```\n",
        "\n",
        "This output is fully structured and aligns with the `UnemploymentDataSource` schema. It makes the data easy to load into tables or use in downstream analytics workflows without additional transformation.\n",
        "\n",
        "## Comparison with LangChain Structured Output {#comparison-with-langchain-structured-output}\n",
        "\n",
        "### How PydanticAI Handles Structured Output {#how-pydanticai-handles-structured-output}\n",
        "\n",
        "PydanticAI returns Pydantic objects directly, so you can immediately access structured fields like `cook_time` without extra parsing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from typing import Optional, List\n",
        "from pydantic import BaseModel\n",
        "from pydantic_ai import Agent\n",
        "\n",
        "class RecipeExtractor(BaseModel):\n",
        "    ingredients: List[str]\n",
        "    instructions: str\n",
        "    cook_time: Optional[str]\n",
        "\n",
        "recipe_agent = Agent(\n",
        "    \"gpt-4o-mini-2024-07-18\",\n",
        "    system_prompt=\"Pull ingredients, instructions, and cook time.\",\n",
        "    output_type=RecipeExtractor,\n",
        ")\n",
        "\n",
        "recipe_result = recipe_agent.run_sync(\n",
        "    \"Sugar, flour, cocoa, eggs, and milk. Mix, bake at 350F for 30 min.\"\n",
        ")\n",
        "print(recipe_result.output.cook_time)\n",
        "# 30 minutes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "PydanticAI simplifies standalone LLM tasks, meaning tasks where you prompt a model once and immediately use the structured output without needing multiple steps, chaining, or external orchestration.\n",
        "\n",
        "### How LangChain Handles Structured Output {#how-langchain-handles-structured-output}\n",
        "\n",
        "[LangChain](https://www.langchain.com/) binds a Pydantic model to the tool, but you must manually extract values from `tool_calls`, adding an extra step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from typing import Optional, List\n",
        "from pydantic import BaseModel\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "# Initialize the chat model\n",
        "model = ChatOpenAI(model=\"gpt-4o-mini-2024-07-18\", temperature=0)\n",
        "\n",
        "# Bind the response formatter schema\n",
        "model_with_tools = model.bind_tools([RecipeExtractor])\n",
        "\n",
        "# Create a list of messages to send to the model\n",
        "messages = [\n",
        "    SystemMessage(\"Pull ingredients, instructions, and cook time.\"),\n",
        "    HumanMessage(\"Sugar, flour, cocoa, eggs, and milk. Mix, bake at 350F for 30 min.\"),\n",
        "]\n",
        "\n",
        "# Invoke the model with the prepared messages\n",
        "ai_msg = model_with_tools.invoke(messages)\n",
        "\n",
        "# Access the tool calls made during the model invocation\n",
        "print(ai_msg.tool_calls[0]['args']['cook_time'])\n",
        "# 30 minutes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "LangChain is better suited for multi-step workflows, such as combining several tools, using routing logic, or building custom chains."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}