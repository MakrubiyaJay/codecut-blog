{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Why You Should Avoid Hard-Coding {#why-you-should-avoid-hard-coding}\n",
        "\n",
        "Here are four major problems caused by hard-coded parameters:\n",
        "\n",
        "### **Maintainability** {#maintainability}\n",
        "\n",
        "Manually updating the same parameter across different files or functions is tedious and error-prone. For example, hard-coding a value like `split_ratio` across multiple scripts can lead to mismatches. If one script updates the value but another doesn't, the code runs inconsistently and is harder to debug:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# script1.py\n",
        "split_ratio = 0.3  # updated value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# script2.py\n",
        "split_ratio = 0.2  # outdated value, not updated"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reusability {#reusability}\n",
        "\n",
        "Hardcoding values limits the reusability of code for different scenarios. For example, the script below is tied to a specific dataset through a hard-coded file path. To use a different dataset, you'd have to manually update the path every time, which is error-prone and slows down iteration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# preprocess.py\n",
        "input_file = \"data/input_v1.csv\"  #needs to be updated manually to \"data/input_v2.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Security** {#security}\n",
        "\n",
        "Hard-coding secrets like API keys, passwords, or database URLs directly into scripts can be a serious risk. The example below shows hard-coded database credentials. If this file is pushed to a shared repository, those credentials could be exposed and lead to unauthorized access to your database."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# config.py\n",
        "db_user = \"admin\"\n",
        "db_password = \"pa55word\"  # hard-coded database credentials"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration Files to the Rescue {#configuration-files-to-the-rescue}\n",
        "\n",
        "Configuration files help improve your workflow in the following ways:\n",
        "\n",
        "### **Cleaner code and easier maintenance** {#cleaner-code-and-easier-maintenance}\n",
        "\n",
        "Keeping configuration separate from logic makes scripts easier to read and maintain. You can change parameters without touching your core code.\n",
        "\n",
        "```yaml\n",
        "# main.yaml\n",
        "data:\n",
        "  raw: data/raw/winequality-red.csv\n",
        "  intermediate: data/intermediate\n",
        "\n",
        "cols_to_drop:\n",
        "  - free sulfur dioxide\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "from omegaconf import OmegaConf\n",
        "\n",
        "config = OmegaConf.load(\"main.yaml\")\n",
        "\n",
        "data = pd.read_csv(config.data.raw)\n",
        "data = data.drop(columns=config.cols_to_drop)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Faster experimentation** {#faster-experimentation}\n",
        "\n",
        "Configuration files allow you to tweak parameters like features, splits, and hyperparameters without modifying the source code, enabling rapid iteration and experimentation.\n",
        "\n",
        "```yaml\n",
        "# main.yaml\n",
        "\n",
        "# Change from this\n",
        "features: [age, income, education]\n",
        "\n",
        "# To this without touching the source code\n",
        "features: [age, income, education, credit_score]\n",
        "```\n",
        "\n",
        "### **Simplified deployment** {#simplified-deployment}\n",
        "\n",
        "With config files, adapting to different environments like development or production is straightforward. You can swap in the right settings without editing any logic.\n",
        "\n",
        "```yaml\n",
        "# conf/database/dev.yaml\n",
        "name: dev\n",
        "db_url: sqlite:///dev.db\n",
        "```\n",
        "\n",
        "```yaml\n",
        "# conf/database/prod.yaml\n",
        "name: prod\n",
        "db_url: postgresql://prod_user:secure@prod.db.example.com/prod\n",
        "```\n",
        "\n",
        "```bash\n",
        "# Run with dev settings\n",
        "python main.py database=dev\n",
        "​\n",
        "# Run with prod settings\n",
        "python main.py database=prod\n",
        "```\n",
        "\n",
        "## Convenient Parameter Access {#convenient-parameter-access}\n",
        "\n",
        "Suppose all configuration files are stored under the `conf` folder, and all Python scripts are stored under the `src` folder.\n",
        "\n",
        "```\n",
        ".\n",
        "├── conf/\n",
        "│   └── main.yaml\n",
        "└── src/\n",
        "    ├── process.py\n",
        "    └── train_model.py\n",
        "```\n",
        "\n",
        "And the `main.yaml` file looks like this:\n",
        "\n",
        "```yaml\n",
        "process:\n",
        "  cols_to_drop:\n",
        "  - free sulfur dioxide\n",
        "  feature: quality\n",
        "  test_size: 0.2\n",
        "train:\n",
        "  hyperparameters:\n",
        "    svm__kernel:\n",
        "    - rbf\n",
        "    svm__C:\n",
        "    - 0.1\n",
        "    - 1\n",
        "    - 10\n",
        "    svm__gamma:\n",
        "    - 0.1\n",
        "    - 1\n",
        "    - 10\n",
        "  grid_search:\n",
        "    cv: 2\n",
        "    scoring: accuracy\n",
        "    verbose: 3\n",
        "data:\n",
        "  raw: data/raw/winequality-red.csv\n",
        "  intermediate: data/intermediate\n",
        "model: models\n",
        "```\n",
        "\n",
        "You can load a configuration file in your Python script by decorating your main function with `@hydra.main`, which tells Hydra where to find and how to apply the configuration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from omegaconf import DictConfig\n",
        "import hydra\n",
        "​\n",
        "@hydra.main(config_path=\"../conf\", config_name=\"main\", version_base=None)\n",
        "def process_data(config: DictConfig):\n",
        "  ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the code above, `config` is an instance of `DictConfig`, a flexible and hierarchical configuration object provided by OmegaConf. It behaves like both a dictionary and an object, allowing you to access parameters using dot notation ( `config.key`) or dictionary-style ( `config['key']`):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# src/process.py\n",
        "import hydra\n",
        "from omegaconf import DictConfig\n",
        "​\n",
        "​\n",
        "@hydra.main(config_path=\"../conf\", config_name=\"main\", version_base=None)\n",
        "def process_data(config: DictConfig):\n",
        "    print(\"Accessing with bracket notation:\", config[\"process\"][\"cols_to_drop\"])\n",
        "    print(\"Accessing with dot notation:\", config.process.cols_to_drop)\n",
        "​\n",
        "​\n",
        "if __name__ == \"__main__\":\n",
        "    process_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Running this Python script is straightforward:\n",
        "\n",
        "```bash\n",
        "python src/process.py\n",
        "```\n",
        "\n",
        "Or use uv, a modern Python CLI tool that replaces pip and Python for running scripts:\n",
        "\n",
        "```bash\n",
        "uv run src/process.py\n",
        "```\n",
        "\n",
        "Output:\n",
        "\n",
        "```python\n",
        "Accessing with bracket notation: ['free sulfur dioxide']\n",
        "Accessing with dot notation: ['free sulfur dioxide']\n",
        "```\n",
        "\n",
        "This straightforward approach allows you to effortlessly retrieve the desired parameters.\n",
        "\n",
        "\n",
        "\n",
        "## Command-line configuration override {#command-line-configuration-override}\n",
        "\n",
        "Let's say you are experimenting with different `test_size`. It is time-consuming to repeatedly open your configuration file and modify the `test_size` value.\n",
        "\n",
        "```yaml\n",
        "# conf/main.yaml\n",
        "process:\n",
        "  cols_to_drop:\n",
        "    - free sulfur dioxide\n",
        "  feature: quality\n",
        "  test_size: 0.3  # previously 0.2\n",
        "```\n",
        "\n",
        "Luckily, Hydra makes it easy to directly overwrite the configuration from the command line.\n",
        "\n",
        "Let's try overriding a parameter at runtime. Start with the following `conf/main.yaml` configuration:\n",
        "\n",
        "```yaml\n",
        "process:\n",
        "  strategy: drop_missing\n",
        "  cols_to_drop:\n",
        "    - id\n",
        "    - timestamp\n",
        "    - customer_id\n",
        "  impute_strategy: null\n",
        "  feature: quality\n",
        "  test_size: 0.2\n",
        "```\n",
        "\n",
        "Then define `src/process.py` as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# src/process.py\n",
        "import hydra\n",
        "from omegaconf import DictConfig, OmegaConf\n",
        "\n",
        "@hydra.main(config_path=\"../conf\", config_name=\"main\", version_base=None)\n",
        "def process_data(config: DictConfig):\n",
        "    # Converts the entire config object to a YAML string for readable output\n",
        "    print(OmegaConf.to_yaml(config))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    process_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now run the script, overriding `test_size` on the command line:\n",
        "\n",
        "```bash\n",
        "uv run src/process.py process.test_size=0.3\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "\n",
        "```yaml\n",
        "process:\n",
        "  strategy: drop_missing\n",
        "  cols_to_drop:\n",
        "  - id\n",
        "  - timestamp\n",
        "  - customer_id\n",
        "  impute_strategy: null\n",
        "  feature: quality\n",
        "  test_size: 0.3\n",
        "```\n",
        "\n",
        "We can see that `test_size` is now 0.3 instead of 0.2!\n",
        "\n",
        "This confirms that the `test_size` value was overridden at runtime, allowing you to test different settings quickly without editing the config file.\n",
        "\n",
        "## Grouping config files {#grouping-config-files}\n",
        "\n",
        "In a data science project, you might have many ways to process your data, each with its own set of parameters. A common approach is to comment and uncomment blocks of configuration code to toggle between them, which leads to cluttered configs:\n",
        "\n",
        "```yaml\n",
        "# conf/main.yaml\n",
        "# process:\n",
        "  # strategy: drop_missing\n",
        "  # cols_to_drop: [\"id\", \"timestamp\", \"customer_id\"]\n",
        "  # impute_strategy: null\n",
        "  # feature: \"quality\"\n",
        "  # test_size: 0.2\n",
        "process:\n",
        "  strategy: impute\n",
        "  cols_to_drop: []\n",
        "  impute_strategy: mean\n",
        "  feature: \"quality\"\n",
        "  test_size: 0.2\n",
        "\n",
        "data:\n",
        "  raw: data/raw/winequality-red.csv\n",
        "  intermediate: data/intermediate\n",
        "```\n",
        "\n",
        "Hydra supports organizing related configurations into groups, making it easier to manage variations of preprocessing steps, models, or training strategies in a clean and modular way.\n",
        "\n",
        "Here's how to set up and use a config group for processing options:\n",
        "\n",
        "First, update your project structure to organize different processing strategies under a `process/` config group:\n",
        "\n",
        "```\n",
        ".\n",
        "└── conf/\n",
        "    ├── main.yaml\n",
        "    └── process/\n",
        "        ├── drop_missing.yaml\n",
        "        └── impute.yaml\n",
        "```\n",
        "\n",
        "Each file in the `process/` folder contains parameters for a specific data preprocessing method. For example:\n",
        "\n",
        "```yaml\n",
        "# conf/process/drop_missing.yaml\n",
        "strategy: drop_missing\n",
        "cols_to_drop: [\"id\", \"timestamp\", \"customer_id\"]\n",
        "impute_strategy: null\n",
        "feature: quality\n",
        "test_size: 0.2\n",
        "```\n",
        "\n",
        "```yaml\n",
        "# conf/process/impute.yaml\n",
        "strategy: impute\n",
        "cols_to_drop: []\n",
        "impute_strategy: mean\n",
        "feature: quality\n",
        "test_size: 0.2\n",
        "```\n",
        "\n",
        "Now, in `main.yaml`, reference the `process` group using Hydra's `defaults` list:\n",
        "\n",
        "```yaml\n",
        "defaults:\n",
        "  - process: drop_missing\n",
        "  - _self_\n",
        "​\n",
        "data:\n",
        "  raw: data/raw/winequality-red.csv\n",
        "  intermediate: data/intermediate\n",
        "```\n",
        "\n",
        "To switch between groups, simply run:\n",
        "\n",
        "```bash\n",
        "uv run src/process.py process=impute\n",
        "```\n",
        "\n",
        "You can also group training strategies the same way:\n",
        "\n",
        "```bash\n",
        "conf/\n",
        "├── main.yaml\n",
        "├── process/\n",
        "│   ├── drop_missing.yaml\n",
        "│   └── impute.yaml\n",
        "└── train/\n",
        "    ├── basic.yaml\n",
        "    └── advanced.yaml\n",
        "```\n",
        "\n",
        "Update `main.yaml` to include both groups:\n",
        "\n",
        "```yaml\n",
        "defaults:\n",
        "  - process: drop_missing\n",
        "  - train: basic\n",
        "  - _self_\n",
        "​\n",
        "data:\n",
        "  raw: data/raw/winequality-red.csv\n",
        "  intermediate: data/intermediate\n",
        "```\n",
        "\n",
        "With this setup, you can mix and match different combinations of processing and training configurations using a single command:\n",
        "\n",
        "```bash\n",
        "uv run src/train_model.py process=impute train=advanced\n",
        "```\n",
        "\n",
        "This approach makes it easy to organize and switch between multiple configurations for data preprocessing, without touching your Python scripts.\n",
        "\n",
        "## Multi-run {#multi-run}\n",
        "\n",
        "When testing multiple processing strategies, running them one at a time can slow down your workflow:\n",
        "\n",
        "```bash\n",
        "uv run src/process.py process=drop_missing\n",
        "# wait for this to finish\n",
        "# then run the application with another configuration\n",
        "uv run src/process.py process=impute\n",
        "```\n",
        "\n",
        "Hydra lets you run the same application across multiple configurations in a single command, eliminating the need to execute each variation manually.\n",
        "\n",
        "```bash\n",
        "uv run src/process.py --multirun process=drop_missing,impute\n",
        "```\n",
        "\n",
        "Output:\n",
        "\n",
        "```bash\n",
        "2025-05-15 11:55:20,260][HYDRA] Launching 2 jobs locally\n",
        "[2025-05-15 11:55:20,260][HYDRA]        #0 : process=drop_missing\n",
        "[2025-05-15 11:55:20,298][HYDRA]        #1 : process=impute\n",
        "```\n",
        "\n",
        "This approach streamlines the process of running an application with various parameters, ultimately saving valuable time and effort."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}